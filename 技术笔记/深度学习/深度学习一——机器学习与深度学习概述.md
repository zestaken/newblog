---
title: 深度学习一——机器学习与深度学习概述
date: 2021-10-25 11:37:19
tags: [深度学习]
categories: 技术笔记
---
# 机器学习与深度学习概述

* **机器学习（machine learning，ML）**是强大的可以从经验中学习的技术。通常采用观测数据或与环境交互的形式，机器学习算法会积累更多的经验，其性能也会逐步提高。
* **深度学习(deep learning)**是机器学习中的一种，是一套强大的技术，它可以推动计算机视觉、自然语言处理、医疗保健和基因组学等不同领域的创新。
* **学习(learning)**: 在机器学习中，*学习*（learning）是一个模型的训练过程。通过这个过程，我们可以发现正确的参数集，从而从使模型强制执行所需的行为。换句话说，我们用数据*训练*（train）我们的模型。训练过程通常包含如下步骤：
    1. 从一个随机初始化参数的模型开始，这个模型基本毫不“智能”。
    2. 获取一些数据样本（例如，音频片段以及对应的$\{\text{是}, \text{否}\}$标签）。
    3. 调整参数，使模型在这些样本中表现得更好。
    4. 重复第2步和第3步，直到模型在任务中的表现令你满意。
    ![GU8YZA](https://zjpicture.oss-cn-beijing.aliyuncs.com/giteePic/picgo-master/uPic/GU8YZA.png)
* 用数据编程：将机器学习这种“通过用数据集来确定程序行为”的方法看作是“用数据编程”（programming with data）。比如，我们可以通过向机器学习系统提供许多猫和狗的图片来设计一个“猫图检测器”。

# 机器学习的关键组件

* **数据(data)**: 我们可以学习的*数据*（data）。
* **模型(model)**: 如何转换数据的*模型*（model）。
* **目标函数objective function）**: 一个*目标函数*，用来量化模型的有效性。
* **优化算法**：调整模型参数以优化目标函数的算法。

## 数据

* **样本(example)**: 每个数据集由一个个*样本*（example）组成，大多时候，它们遵循独立同分布(independently and identically distributed, i.i.d.)。样本有时也叫做*数据点*（data point）或者*数据实例*（data instance），通常每个样本由一组称为*特征*（features，或*协变量*（covariates））的属性组成。机器学习模型会根据这些属性进行预测。在监督学习问题中，要预测的是一个特殊的属性，它被称为*标签*（label），或*目标*（target））。
    * 假设我们处理的是图像数据，每一张单独的照片即为一个样本，它的特征由每个像素数值的有序列表表示。比如，$200\times 200$彩色照片由$200\times200\times3=120000$个数值组成，其中的“3”对应于每个空间位置的红、绿、蓝通道的强度。
* **维数（dimensionality）**：当每个样本的特征类别数量都是相同的，所以其特征向量是固定长度的，这个长度被称为数据的*维数*。固定长度的特征向量是一个方便的属性，它有助于我们量化学习大量样本。然而，并不是所有的数据都可以用“固定长度”的向量表示。例如，文本数据就不符合“固定长度”的要求。与传统机器学习方法相比，*深度学习的一个主要优势是可以处理不同长度的数据*。
* 大量且正确的数据：在没有大数据集的情况下，许多令人兴奋的深度学习模型黯然失色。就算一些深度学习模型在小数据集上能够工作，但其效能并不比传统方法高。但是，仅仅拥有海量的数据是不够的，我们还需要正确的数据。如果数据中充满了错误，或者如果数据的特征不能预测任务目标，那么模型很可能无效。

## 模型

* 深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为*深度学习*（deep learning）。

## 目标函数

* 在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，我们称之为*目标函数*（objective function）。
* 我们通常定义一个目标函数，并希望优化它到最低点。因为越低越好，所以这些函数有时又被称为*损失函数*（loss function, 或cost function）。
* 通常，损失函数是根据模型参数定义的，并取决于数据集。在一个数据集上，我们通过最小化总损失来学习模型参数的最佳值。
    * 该数据集由一些为训练而收集的样本组成，称为*训练数据集*（training dataset，或称为*训练集*（training set））。
    * 然而，在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的效能，这里的“新数据集”通常称为*测试数据集*（test dataset，或称为*测试集*（test set））。
* 我们通常将可用数据集分成两部分：训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。
* **“过拟合”（overfitting）**：当一个模型在训练集上表现良好，但不能推广到测试集时，我们说这个模型是“过拟合”（overfitting）的。

## 优化算法

* 一旦我们获得了一些数据源及其表示、一个模型和一个合适的损失函数，我们接下来就需要一种算法，它能够搜索出最佳参数，以最小化损失函数。
* **梯度下降（gradient descent）**：深度学习中，大多流行的优化算法通常基于一种基本方法--梯度下降。
    * 简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果你仅对该参数进行少量变动，训练集损失会朝哪个方向移动。然后，它在可以减少损失的方向上优化参数。

# 机器学习基本类型


## 监督学习

* **监督学习（supervised learning）**：擅长在“给定输入特征”的情况下预测标签。
    * 每个“特征-标签”对都称为一个*样本*（example）。有时，即使标签是未知的，样本也可以指代输入特征。
    * 我们的目标是生成一个模型，能够将任何输入特征映射到标签，即预测。
* 监督学习之所以发挥作用，是因为在训练参数时，我们为模型提供了一个数据集，其中每个样本都有真实的标签。用概率论术语来说，我们希望预测“估计给定输入特征的标签”的条件概率。因为在一定程度上，许多重要的任务可以清晰地描述为：在给定一组特定的可用数据的情况下，估计未知事物的概率。
* 监督学习的学习过程如下所示。
    1. 从已知大量数据样本中随机选取一个子集，为每个样本获取基本的真实标签。
    2. 有时，这些样本已有标签（例如，患者是否在下一年内康复？）；有时，我们可能需要人工标记数据（例如，将图像分类）。
    3. 这些输入和相应的标签一起构成了训练数据集。随后，我们选择有监督的学习算法，它将训练数据集作为输入，并输出一个“完成学习模型”。
    4. 我们将之前没见过的样本特征放到这个“完成学习模型”中，使用模型的输出作为相应标签的预测。
![](https://zjpicture.oss-cn-beijing.aliyuncs.com/img/20211023193740.png)
* 即使使用简单的描述“给定输入特征的预测标签”，监督学习也可以采取多种形式的模型，并且需要大量不同的建模决策，这取决于输入和输出的类型、大小和数量。下面介绍一些监督学习的类型。

### 回归

* *回归*（regression）是最简单的监督学习任务之一。当标签取任意数值时，我们称之为*回归*问题。我们的目标是生成一个模型，它的预测非常接近实际标签值。
* 判断回归问题的一个很好的经验法则是，任何有关“多少”的问题很可能就是回归问题。比如，预测用户对一部电影的评分可以被认为是一个回归问题。再比如，预测病人在医院的住院时间也是一个回归问题。

### 分类

* “哪一个？”的问题叫做*分类*（classification）问题。虽然回归模型可以很好地解决“有多少？”的问题，但是很多问题并非如此。
* 在*分类*问题中，我们希望模型能够预测样本属于哪个*类别*（category，正式称为*类*（class））。例如，对于手写数字，我们可能有10类，分别数字0到9。
* **二元分类**：最简单的分类问题是只有两类，我们称之为“二元分类”。
* **分类器**：在分类中，我们训练一个分类器，它的输出即为预测的类别。
* **多类分类**：当我们有两个以上的类别时，我们把这个问题称为*多类分类*（multiclass classification）问题。常见的例子包括手写字符识别 $\mathrm{\{0, 1, 2, ... 9, a, b, c, ...\}}$。
* **交叉熵（cross-entropy）**: 与解决回归问题不同，分类问题的常见损失函数被称为*交叉熵*（cross-entropy）。

### 标记问题

* **多标签分类（multilabel classification）**: 学习预测不相互排斥的类别的问题称为*多标签分类*。举个例子，人们在技术博客上贴的标签，比如“机器学习”、“技术”、“小工具”、“编程语言”、“Linux”、“云计算”、“AWS”。

### 搜索


* 在信息检索领域，我们希望对一组项目进行排序。以网络搜索为例，我们的目标不是简单的“查询（query）-网页（page）”分类，而是在海量搜索结果中找到用户最需要的那部分。
* 搜索结果的排序也十分重要，我们的学习算法需要输出有序的元素子集。即使结果集是相同的，集内的顺序有时却很重要。
* 该问题的一种可能的解决方案：首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素。
* 搜索引擎使用机器学习和用户行为模型来获取网页相关性得分。

### 推荐系统

* 另一类与搜索和排名相关的问题是*推荐系统*（recommender system），它的目标是向给特定用户进行“个性化”推荐。
* 对于任何给定的用户，推荐系统都可以检索得分最高的对象集，然后将其推荐给用户。
* 推荐系统算法经过调整，可以捕捉一个人的偏好。

### 序列学习

* 序列学习需要摄取输入序列或预测输出序列，或两者兼而有之。具体来说，输入和输出都是可变长度的序列，例如机器翻译和从语音中转录文本。
* **标记和解析**。这涉及到用属性注释文本序列。换句话说，输入和输出的数量基本上是相同的。目标是基于结构和语法假设对文本进行分解和注释，以获得一些注释。
    * 下面是一个非常简单的示例，它使用标记来注释一个句子，该标记指示哪些单词引用命名实体(标记为“Ent”，是*实体*（entity）的简写)。
```text
Tom has dinner in Washington with Sally
Ent  -    -    -     Ent      -    Ent
```
* **自动语音识别**。在语音识别中，输入序列是说话人的录音，输出序列是说话人所说内容的文本记录。它的挑战在于，与文本相比，音频帧多得多（声音通常以8kHz或16kHz采样）。也就是说，音频和文本之间没有1:1的对应关系，因为数千个样本可能对应于一个单独的单词。这也是“序列到序列”的学习问题，其中输出比输入短得多。
* **文本到语音**。这与自动语音识别相反。换句话说，输入是文本，输出是音频文件。在这种情况下，输出比输入长得多。
* **机器翻译**。在语音识别中，输入和输出的出现顺序基本相同。而在机器翻译中，颠倒输入和输出的顺序非常重要。换句话说，虽然我们仍将一个序列转换成另一个序列，但是输入和输出的数量以及相应序列的顺序大都不会相同。

## 无监督学习

* 我们称这类数据中不含有“目标”的机器学习问题为*无监督学习*（unsupervised learning），
* **聚类（clustering）**问题：没有标签的情况下，我们是否能给数据分类呢？比如，给定一组照片，我们能把它们分成风景照片、狗、婴儿、猫和山峰的照片吗？同样，给定一组用户的网页浏览记录，我们能否将具有相似行为的用户聚类吗？
* **主成分分析（principal component analysis）**问题：我们能否找到少量的参数来准确地捕捉数据的线性相关属性？比如，一个球的运动轨迹可以用球的速度、直径和质量来描述。再比如，裁缝们已经开发出了一小部分参数，这些参数相当准确地描述了人体的形状，以适应衣服的需要。
* **因果关系（causality）**和**概率图模型（probabilistic graphical models）**问题：我们能否描述观察到的许多数据的根本原因？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和工资的人口统计数据，我们能否简单地根据经验数据发现它们之间的关系？
* **生成对抗性网络*（generative adversarial networks）**：为我们提供一种合成数据的方法，甚至像图像和音频这样复杂的结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域。

## 强化学习

* 如果你对使用机器学习开发与环境交互并采取行动感兴趣，那么你最终可能会专注于*强化学习*（reinforcement learning）。这可能包括应用到机器人、对话系统，甚至开发视频游戏的人工智能（AI）。
* **深度强化学习（deep reinforcement learning）**:将深度学习应用于强化学习的问题，是非常热门的研究领域。
* AlphaGo 程序在棋盘游戏围棋中击败了世界冠军，是两个突出强化学习的例子。
* 在强化学习问题中，agent 在一系列的时间步骤上与环境交互。在每个特定时间点，agent 从环境接收一些*观察*（observation），并且必须选择一个*动作*（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后 agent 从环境中获得 *奖励*（reward）。此后新一轮循环开始，agent 接收后续观察，并选择后续操作，依此类推。请注意，强化学习的目标是产生一个好的*策略*（policy）。强化学习 agent 的选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。
![SHgSpK](https://zjpicture.oss-cn-beijing.aliyuncs.com/giteePic/picgo-master/uPic/SHgSpK.png)
* 我们可以将任何监督学习问题转化为强化学习问题。假设我们有一个分类问题，我们可以创建一个强化学习agent，每个分类对应一个“动作”。然后，我们可以创建一个环境，该环境给予agent的奖励。这个奖励与原始监督学习问题的损失函数是一致的。
* 强化学习还可以解决许多监督学习无法解决的问题。例如，在监督学习中，我们总是希望输入与正确的标签相关联。但在强化学习中，我们并不假设环境告诉agent每个观测的最优动作。一般来说，agent只是得到一些奖励。
* 强化学习者必须处理*学分分配*（credit assignment）问题：决定哪些行为是值得奖励的，哪些行为是需要惩罚的。
* 强化学习可能还必须处理部分可观测性问题。也就是说，当前的观察结果可能无法阐述有关当前状态的所有信息。
* 当环境可被完全观察到时，我们将强化学习问题称为*马尔可夫决策过程*（markov decision process）。
* 当状态不依赖于之前的操作时，我们称该问题为*上下文赌博机*（contextual bandit problem）。
* 当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的*多臂赌博机*（multi-armed bandit problem）。
