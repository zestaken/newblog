---
title: 深度学习十三——卷积神经网络
date: 2021-12-01 14:32:19
tags: [深度学习]
categories: 技术笔记
mathjax: true
---

# 卷积理论概述

* 卷积神经网络（convolutional neural network，CNN）是一类强大的、为处理图像数据而设计的神经网络。 基于卷积神经网络结构的模型在计算机视觉领域中已经占主导地位，当今几乎所有的图像识别、对象检测或语义分割相关的学术竞赛和商业应用都以这种方法为基础。
* 所有卷积网络主干的基本元素包括：卷积层本身、填充（padding）和步幅（stride）、用于在相邻区域的汇聚层（pooling）、在每一层中多通道（channel）的使用。

## 从全连接层到卷积

* 我们之前讨论的多层感知机十分适合处理表格数据，其中行对应样本，列对应特征。然而对于高维感知数据，这种缺少结构的网络可能会变得不实用。
* 例如，在之前猫狗分类的例子中：假设我们有一个足够充分的照片数据集，数据集中是拥有标注的照片，每张照片具有百万级像素，这意味着网络的每次输入都有一百万个维度（即把一个图像展开为一维向量，一个像素是一个特征值）。这个模型将有超乎想象数量的参数，训练这样的模型将不可能实现。
* 然而，如今人类和机器都能很好地区分猫和狗：这是因为图像中本就拥有丰富的结构，而这些结构可以被人类和机器学习模型使用。*卷积神经网络*（convolutional neural networks，CNN）是机器学习*利用自然图像中一些已知结构*的创造性方法。

## 不变性

* 假设你想从一张图片中找到某个物体。合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关。
* 卷积神经网络正是将*空间不变性*（spatial invariance）的这一概念系统化，从而基于这个模型使用较少的参数来学习有用的表示。
* 现在，我们将上述想法总结一下，从而帮助我们设计适合于计算机视觉的神经网络结构：
    1. *平移不变性*（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。
    2. *局部性*（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，在后续神经网络，整个图像级别上可以集成这些局部特征用于预测。
* 下面，让我们看看这些原则是如何转化为数学表示的。

## 限制多层感知机

* 首先，多层感知机的输入是二维图像$\mathbf{X}$，其隐藏表示 $\mathbf{H}$ 在数学上是一个矩阵，在代码中表示为二维张量。
    * 其中 $\mathbf{X}$ 和 $\mathbf{H}$ 具有相同的形状。为了方便理解，我们可以认为，无论是输入还是隐藏表示都拥有空间结构。
* 使用  $[\mathbf{X}]_{i, j}$ 和 $[\mathbf{H}]_{i, j}$ 分别表示输入图像和隐藏表示中位置($i$, $j$)处的像素。
* 为了使每个隐藏神经元都能接收到每个输入像素的信息，我们将参数从权重矩阵（如同我们先前在多层感知机中所做的那样）替换为四阶权重张量 $\mathsf{W}$。假设 $\mathbf{U}$ 包含偏置参数，我们可以将全连接层形式化地表示为：

    $$\begin{aligned} \left[\mathbf{H}\right]_{i, j} &= [\mathbf{U}]_{i, j} + \sum_k \sum_l[\mathsf{W}]_{i, j, k, l}  [\mathbf{X}]_{k, l}\\ &=  [\mathbf{U}]_{i, j} +
\sum_a \sum_b [\mathsf{V}]_{i, j, a, b}  [\mathbf{X}]_{i+a, j+b}.\end{aligned}$$
    * 其中，从 $\mathsf{W}$ 到 $\mathsf{V}$ 的转换只是形式上的转换，因为在这两个四阶张量的元素之间存在一一对应的关系。
* 我们只需重新索引下标 $(k, l)$，使 $k = i+a$、$l = j+b$， 由此可得 $[\mathsf{V}]_{i, j, a, b} = [\mathsf{W}]_{i, j, i+a, j+b}$。
    * 索引 $a$ 和 $b$ 通过在正偏移和负偏移之间移动覆盖了整个图像。
* 对于隐藏表示中任意给定位置（$i$, $j$）处的像素值$[\mathbf{H}]_{i, j}$，可以通过在 $x$ 中以 $(i, j)$ 为中心对像素进行加权求和得到，加权使用的权重为 $[\mathsf{V}]_{i, j, a, b}$ 。

### 平移不变性

* 平移不变性：意味着检测对象在输入 $\mathbf{X}$ 中的平移，应该仅仅导致隐藏表示 $\mathbf{H}$ 中的平移。也就是说， $\mathsf{V}$ 和 $\mathbf{U}$ 实际上不依赖于 $(i, j)$ 的值，即 $[\mathsf{V}]_{i, j, a, b} = [\mathbf{V}]_{a, b}$。并且  $\mathbf{U}$ 是一个常数，比如 $u$。因此，我们可以简化 $\mathbf{H}$ 定义为：
    $$[\mathbf{H}]_{i, j} = u + \sum_a\sum_b [\mathbf{V}]_{a, b} [\mathbf{X}]_{i+a, j+b}.$$
* 这就是 *卷积* （convolution）。我们是在使用系数 $[\mathbf{V}]_{a, b}$ 对位置 $(i, j)$ 附近的像素 $(i+a, j+b)$ 进行加权得到$[\mathbf{H}]_{i, j}$。
* 注意，$[\mathbf{V}]_{a, b}$ 的系数比 $[\mathsf{V}]_{i, j, a, b}$ 少很多，因为前者不再依赖于图像中的位置。这就是显著的进步！

### 局部性

* 局部性：如上所述，为了收集用来训练参数 $[\mathbf{H}]_{i, j}$ 的相关信息，我们不应偏离到距 $(i, j)$ 很远的地方。这意味着在 $|a|> \Delta$ 或 $|b| > \Delta$ 的范围之外，我们可以设置 $[\mathbf{V}]_{a, b} = 0$。因此，我们可以将 $[\mathbf{H}]_{i, j}$ 重写为
    $$[\mathbf{H}]_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}.$$
* 简而言之， 以上公式就是一个 *卷积层* （convolutional layer）得表示，而卷积神经网络是包含卷积层的一类特殊的神经网络。
    * 在深度学习中， $\mathbf{V}$ 被称为 *卷积核* （convolution kernel） 或者  *滤波器* （filter），它仅仅是可学习的一个层的权重。
* 当图像处理的局部区域很小时，卷积神经网络与多层感知机的训练差异可能是巨大的：以前，多层感知机可能需要数十亿个参数来表示网络中的一层，而现在卷积神经网络通常只需要几百个参数，而且不需要改变输入或隐藏表示的维数。
    * 参数大幅减少的代价是，我们的特征现在是平移不变的，并且当确定每个隐藏激活的值时，每一层只能包含局部的信息。
* 以上所有的权重学习都将依赖于归纳偏置。
    * 当这种偏置与现实相符时，我们就能得到样本有效的模型，并且这些模型能很好地泛化到未知数据中。
    * 但如果这偏置与现实不符时，比如当图像不满足平移不变时，我们的模型可能难以拟合我们的训练数据。

## 卷积

* 在数学中，两个函数（比如 $f, g: \mathbb{R}^d \to \mathbb{R}$）之间的“卷积”被定义为
    $$(f * g)(\mathbf{x}) = \int f(\mathbf{z}) g(\mathbf{x}-\mathbf{z}) d\mathbf{z}.$$
* 也就是说，卷积是测量 $f$ 和 $g$ 之间（把其中一个函数“翻转”并移位 $\mathbf{x}$ 时）的重叠。
* 当我们有离散对象时，积分就变成求和。例如：对于由索引为$\mathbb{Z}$的、平方可和的、无限维向量集合中抽取的向量，我们得到以下定义：
    $$(f * g)(i) = \sum_a f(a) g(i-a).$$
* 对于二维张量，则为 $f$ 的索引 $(a, b)$ 和 $g$ 的索引 $(i-a, j-b)$ 上的对应和：
    $$(f * g)(i, j) = \sum_a\sum_b f(a, b) g(i-a, j-b).$$
* 这个公式看起来类似于局部性部分的表述，但有一个主要区别：这里不是使用 $(i+a, j+b)$ ，而是使用差值。

### 通道

* 图像一般包含三个通道/三种原色（红色、绿色和蓝色）。
* 实际上，图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量，比如包含 $1024 \times 1024 \times 3$ 个像素。
    * 前两个轴与像素的空间位置有关，而第三个轴可以看作是每个像素的多维表示。
    * 因此，我们将 $\mathsf{X}$ 索引为 $[\mathsf{X}]_{i, j, k}$ 。由此卷积相应地调整为 $[\mathsf{V}]_{a,b,c}$ ，而不是 $[\mathbf{V}]_{a,b}$ 。
* 此外，由于输入图像是三维的，我们的隐藏表示 $\mathsf{H}$ 也最好采用三维张量。换句话说，对于每一个空间位置，我们想要采用一组而不是一个隐藏表示。这样一组隐藏表示可以想象成一些互相堆叠的二维网格。
    * 因此，我们可以把隐藏表示想象为一系列具有二维张量的 *通道* （channel）。
    * 这些通道有时也被称为 *特征映射* （feature maps），因为每个通道都向后续层提供一组空间化的学习特征。直观上你可以想象在靠近输入的底层，一些通道专门识别边，而其他通道专门识别纹理。
* 为了支持输入 $\mathsf{X}$ 和隐藏表示 $\mathsf{H}$ 中的多个通道，我们可以在 $\mathsf{V}$ 中添加第四个坐标，即 $[\mathsf{V}]_{a, b, c, d}$ 。综上所述：
    $$[\mathsf{H}]_{i,j,d} = \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} \sum_c [\mathsf{V}]_{a, b, c, d} [\mathsf{X}]_{i+a, j+b, c},$$
    * 其中隐藏表示 $\mathsf{H}$ 中的 $d$ 索引表示输出通道，而随后的输出将继续以三维张量 $\mathsf{H}$ 作为输入进入下一个卷积层。
    * 所以，上述公式可以定义具有多个通道的卷积层，而其中 $\mathsf{V}$ 是该卷积层的权重。

# 图像卷积

* 我们解析了卷积层的原理之后，现在我们看看它的实际应用。由于卷积神经网络的设计是用于探索图像数据，所以我们将以图像为例。

## 互相关运算

* 严格来说，卷积层是个错误的叫法，因为它所表达的运算其实是 *互相关运算* (cross-correlation)，而不是卷积运算。在卷积层中，输入张量和核张量（也叫过滤器)通过(**互相关运算**)产生输出张量。
* 首先，我们暂时忽略通道（第三维）这一情况，看看如何处理二维图像数据和隐藏表示。在下图中，输入是高度为 $3$ 、宽度为 $3$ 的二维张量（即形状为 $3 \times 3$ ）。卷积核的高度和宽度都是 $2$ ，而卷积核窗口（或卷积窗口）的形状由内核的高度和宽度决定（即 $2 \times 2$ ）。

![lPUHs5](https://zjpicture.oss-cn-beijing.aliyuncs.com/giteePic/picgo-master/uPic/lPUHs5.png)
* 在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。当卷积窗口滑动到新一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个*单一的标量值，由此我们得出了这一位置的输出张量值*。
* 在如上例子中，输出张量的四个元素由二维互相关运算得到，这个输出高度为 $2$ 、宽度为 $2$ ，如下所示：
    $$
    0\times0+1\times1+3\times2+4\times3=19,\\
    1\times0+2\times1+4\times2+5\times3=25,\\
    3\times0+4\times1+6\times2+7\times3=37,\\
    4\times0+5\times1+7\times2+8\times3=43.
    $$
    * 注意，输出大小略小于输入大小。这是因为卷积核的宽度和高度大于1，而卷积核只与图像中每个大小完全适合的位置进行互相关运算。所以，输出大小等于输入大小 $n_h \times n_w$ 减去卷积核大小 $k_h \times k_w$，即：
    $$(n_h-k_h+1) \times (n_w-k_w+1).$$
    * 这是因为我们需要足够的空间在图像上“移动”卷积核。之后，我们将学习如何通过在图像边界周围填充零来保证有足够的空间移动内核，从而保持输出大小不变。
* 接下来，我们在 `corr2d` 函数中实现如上过程，该函数接受输入张量 `X` 和卷积核张量  `K` ，并返回输出张量 `Y` 。
    * 注：[tensorflow 中assign运算符的使用](https://blog.csdn.net/Invokar/article/details/89041501)


```python
import tensorflow as tf
from d2l import tensorflow as d2l

def corr2d(X, K):  #@save
    """计算二维互相关运算。"""
    h, w = K.shape # 卷积核张量的形状
    Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))) # 初始化一个张量为0接受运算输出
    for i in range(Y.shape[0]): # 纵向
        for j in range(Y.shape[1]): # 横向
            Y[i, j].assign(tf.reduce_sum( # assign运算赋值
                X[i: i + h, j: j + w] * K)) # reduce_sum算矩阵对应元素乘积的和
    return Y
```

* 下面我们来[**验证上述二维互相关运算的输出**]。


```python
X = tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
K = tf.constant([[0.0, 1.0], [2.0, 3.0]])
corr2d(X, K) # 与图中完全一致
```




    <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=
    array([[19., 25.],
           [37., 43.]], dtype=float32)>



## 卷积层

* 卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。所以，卷积层中的两个被训练的参数是**卷积核权重和标量偏置**。
* 就像我们之前随机初始化全连接层一样，在训练基于卷积层的模型时，我们也随机初始化卷积核权重。
* 高度和宽度分别为$h$和$w$的卷积核可以被称为$h \times w$卷积或$h \times w$卷积核。 我们也将带有$h \times w$卷积核的卷积层称为$h \times w$ 卷积层。
* 下面代码基于上面定义的 `corr2d` 函数[**实现二维卷积层**]。在 `__init__` 构造函数中，将 `weight` 和 `bias` 声明为两个模型参数。前向传播函数调用 `corr2d` 函数并添加偏置。


```python
class Conv2D(tf.keras.layers.Layer): # 继承
    def __init__(self):
        super().__init__()

    def build(self, kernel_size):
        initializer = tf.random_normal_initializer()  # 初始化器
        self.weight = self.add_weight(name='w', shape=kernel_size,
                                      initializer=initializer) # 卷积核权重
        self.bias = self.add_weight(name='b', shape=(1, ), # 标量偏置
                                    initializer=initializer)

    def call(self, inputs):
        return corr2d(inputs, self.weight) + self.bias # 模型核心运算为互相关运算加上偏置（会广播）
```

## 图像中目标的边缘检测

* 如下是卷积层的一个简单应用: 通过找到像素变化的位置，来(**检测图像中不同颜色的边缘**)。
* 首先，我们构造一个 $6\times 8$ 像素的黑白图像。中间四列为黑色（$0$），其余像素为白色（$1$）。


```python
X = tf.Variable(tf.ones((6, 8)))
X[:, 2:6].assign(tf.zeros(X[:, 2:6].shape))
X
```




    <tf.Variable 'Variable:0' shape=(6, 8) dtype=float32, numpy=
    array([[1., 1., 0., 0., 0., 0., 1., 1.],
           [1., 1., 0., 0., 0., 0., 1., 1.],
           [1., 1., 0., 0., 0., 0., 1., 1.],
           [1., 1., 0., 0., 0., 0., 1., 1.],
           [1., 1., 0., 0., 0., 0., 1., 1.],
           [1., 1., 0., 0., 0., 0., 1., 1.]], dtype=float32)>



* 接下来，我们构造一个高度为 $1$ 、宽度为 $2$ 的卷积核 `K` 。当进行互相关运算时，如果水平相邻的两元素相同，则输出为零，否则输出为非零。


```python
K = tf.constant([[1.0, -1.0]])
```

* 现在，我们对参数 `X` （输入）和 `K` （卷积核）执行互相关运算。如下所示，[**输出`Y`中的1代表从白色到黑色的边缘，-1代表从黑色到白色的边缘**]，其他情况的输出为 $0$。


```python
Y = corr2d(X, K)
Y
```




    <tf.Variable 'Variable:0' shape=(6, 7) dtype=float32, numpy=
    array([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],
           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
           [ 0.,  1.,  0.,  0.,  0., -1.,  0.]], dtype=float32)>



* 现在我们将输入的二维图像转置(即将垂直边缘转换为水平边缘），再进行如上的互相关运算进行检测边缘。其输出如下，没能检测出任何边缘。不出所料，这个[**卷积核`K`只可以检测垂直边缘**]，无法检测水平边缘。


```python
corr2d(tf.transpose(X), K)
```




    <tf.Variable 'Variable:0' shape=(8, 5) dtype=float32, numpy=
    array([[0., 0., 0., 0., 0.],
           [0., 0., 0., 0., 0.],
           [0., 0., 0., 0., 0.],
           [0., 0., 0., 0., 0.],
           [0., 0., 0., 0., 0.],
           [0., 0., 0., 0., 0.],
           [0., 0., 0., 0., 0.],
           [0., 0., 0., 0., 0.]], dtype=float32)>



## 学习卷积核

* 如果我们只需寻找黑白边缘，那么以上 `[1, -1]` 的边缘检测器足以。然而，当有了更复杂数值的卷积核，或者连续的卷积层时，我们不可能手动设计过滤器（即卷积核）。所以我们需要[**学习由`X`生成`Y`的卷积核**]。
* 现在让我们看看是否可以通过仅查看“输入-输出”对来学习由 `X` 生成 `Y` 的卷积核。
* 我们先构造一个卷积层，并将其卷积核初始化为随机张量。接下来，在每次迭代中，我们比较  `Y` 与卷积层输出的平方误差，然后计算梯度来更新卷积核。为了简单起见，我们在此使用内置的二维卷积层，并忽略偏置。


```python
# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核
conv2d = tf.keras.layers.Conv2D(1, (1, 2), use_bias=False)

# 这个二维卷积层使用四维输入和输出格式（批量大小、高度、宽度、通道），
# 其中批量大小和通道数都为1
X = tf.reshape(X, (1, 6, 8, 1))
Y = tf.reshape(Y, (1, 6, 7, 1)) # 实际的边缘结果

Y_hat = conv2d(X) # 由卷积层检测的边缘结果
for i in range(10):
    with tf.GradientTape(watch_accessed_variables=False) as g:
        g.watch(conv2d.weights[0]) # 记录权重，用于计算偏导优化权重参数
        Y_hat = conv2d(X)
        l = (abs(Y_hat - Y)) ** 2 # 计算损失值
        # 迭代卷积核
        update = tf.multiply(3e-2, g.gradient(l, conv2d.weights[0])) # 更新权重的值
        weights = conv2d.get_weights() 
        weights[0] = conv2d.weights[0] - update
        conv2d.set_weights(weights)
        if (i + 1) % 2 == 0: # 每两次训练打印一次损失值
            print(f'batch {i+1}, loss {tf.reduce_sum(l):.3f}')
```

    batch 2, loss 10.258
    batch 4, loss 3.103
    batch 6, loss 1.087
    batch 8, loss 0.414
    batch 10, loss 0.164
    

* 在 $10$ 次迭代之后，误差已经降到足够低。现在我们来看看我们[**所学的卷积核的权重张量**]。


```python
tf.reshape(conv2d.get_weights()[0], (1, 2))
```




    <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 1.0303406 , -0.94749206]], dtype=float32)>



* 我们学习到的卷积核权重非常接近我们之前定义的卷积核 `K` 。

# 填充和步幅

* 假设输入形状为 $n_h\times n_w$，卷积核形状为 $k_h\times k_w$，那么输出形状将是$(n_h-k_h+1) \times (n_w-k_w+1)$。因此，卷积的输出形状取决于输入形状和卷积核的形状。
* 但是，有时我们需要控制输出的形状，这就需要 *填充*（padding）和 *步幅* (stride)。
    * 假设以下情景：有时，在应用了连续的卷积之后，我们最终得到的输出远小于输入大小。这是由于卷积核的宽度和高度通常大于 $1$ 所导致的。比如，一个 $240 \times 240$ 像素的图像，经过 $10$ 层 $5 \times 5$ 的卷积后，将减少到 $200 \times 200$ 像素。如此一来，原始图像的边界丢失了许多有用信息。 而*填充* 是解决此问题最有效的方法。
    * 有时，我们可能希望大幅降低图像的宽度和高度。例如，如果我们发现原始的输入分辨率十分冗余。 *步幅*则可以在这类情况下提供帮助。

## 填充

* 在应用多层卷积时，我们常常丢失边缘像素。由于我们通常使用小卷积核，因此对于任何单个卷积，我们可能只会丢失几个像素。但随着我们应用许多连续卷积层，累积丢失的像素数就多了。解决这个问题的简单方法即为*填充*（padding）：在输入图像的边界填充元素（通常填充元素是 $0$ ）。
    * 例如，在下图中，我们将 $3 \times 3$ 输入填充到 $5 \times 5$，那么它的输出就增加为 $4 \times 4$。阴影部分是第一个输出元素以及用于输出计算的输入和核张量元素：
$0\times0+0\times1+0\times2+0\times3=0$。
    ![](https://zjpicture.oss-cn-beijing.aliyuncs.com/img/20211127182509.png)
* 通常，如果我们添加 $p_h$ 行填充（大约一半在顶部，一半在底部）和 $p_w$ 列填充（左侧大约一半，右侧一半），则输出形状将为：
    $$(n_h-k_h+p_h+1)\times(n_w-k_w+p_w+1)。$$
    * 这意味着输出的高度和宽度将分别增加 $p_h$ 和 $p_w$。
* 在许多情况下，我们需要设置 $p_h=k_h-1$ 和 $p_w=k_w-1$，使*输入和输出具有相同的高度和宽度*。这样可以在构建网络时更容易地预测每个图层的输出形状。假设 $k_h$ 是奇数，我们将在高度的两侧填充 $p_h/2$ 行。如果 $k_h$ 是偶数，则一种可能性是在输入顶部填充 $\lceil p_h/2\rceil$ 行，在底部填充 $\lfloor p_h/2\rfloor$ 行。同理，我们填充宽度的两侧。
* 卷积神经网络中卷积核的高度和宽度通常为奇数，例如 1、3、5 或 7。选择奇数的好处是，保持空间维度的同时，我们可以在顶部和底部填充相同数量的行，在左侧和右侧填充相同数量的列。
* 此外，使用奇数核和填充也提供了书写上的便利。对于任何二维张量 `X`，当满足以下三个条件时， 则可以得出：输出 `Y[i, j]` 是通过以输入 `X[i, j]` 为中心，与卷积核进行互相关计算得到的。：
    1. 内核的大小是奇数；
    2. 所有边的填充行数和列数相同；
    3. 输出与输入具有相同高度和宽度
* 比如，在下面的例子中，我们创建一个高度和宽度为3的二维卷积层，并(**在所有侧边填充1个像素**)。给定高度和宽度为8的输入，则输出的高度和宽度也是8。
    * 创建卷积层时，通过padding参数来设置在计算卷积时自动填充输入张量，使输出与输入维数相同。


```python
import tensorflow as tf

# 为了方便起见，我们定义了一个计算卷积层的函数。
# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数
def comp_conv2d(conv2d, X):
    # 这里的（1，1）表示批量大小和通道数都是1
    X = tf.reshape(X, (1, )+ X.shape + (1, )) # 即将X的形状变为（1，8，8，1）
    Y = conv2d(X)
    # 省略前两个维度：批量大小和通道
    return tf.reshape(Y, Y.shape[1:3])

# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列
# 通过padding参数再计算卷积时自动填充输入，使输出与输入维数相同
conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same')
X = tf.random.uniform(shape=(8, 8))
comp_conv2d(conv2d, X).shape # 维数也是（8，8）
```




    TensorShape([8, 8])



* 当卷积内核的高度和宽度不同时，我们可以[**填充不同的高度和宽度**]，使输出和输入具有相同的高度和宽度。在如下示例中，我们使用高度为5，宽度为3的卷积核，高度和宽度两边的填充分别为2和1。也可以使输出和输入形状相同。


```python
conv2d = tf.keras.layers.Conv2D(1, kernel_size=(5, 3), padding='same')
comp_conv2d(conv2d, X).shape # 形状仍为(8, 8)
```




    TensorShape([8, 8])



## 步幅

* 在计算互相关时，卷积窗口从输入张量的左上角开始，向下和向右滑动。在前面的例子中，我们默认每次滑动一个元素。有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。
* 我们将每次滑动元素的数量称为 *步幅* （stride）。
* 下图是垂直步幅为 $3$，水平步幅为 $2$ 的二维互相关运算。
    * 着色部分是输出元素以及用于输出计算的输入和内核张量元素：$0\times0+0\times1+1\times2+2\times3=8$；$0\times0+6\times1+0\times2+0\times3=6$。
    * 可以看到，为了计算输出中第一列的第二个元素和第一行的第二个元素，卷积窗口分别向下滑动三行和向右滑动两列。但是，当卷积窗口继续向右滑动两列时，没有输出，因为输入元素无法填充窗口（除非我们添加另一列填充）。
    ![](https://zjpicture.oss-cn-beijing.aliyuncs.com/img/20211127185121.png)
* 通常，当垂直步幅为 $s_h$ 、水平步幅为 $s_w$ 时，输出形状为
    $$\lfloor(n_h-k_h+p_h+s_h)/s_h\rfloor \times \lfloor(n_w-k_w+p_w+s_w)/s_w\rfloor.$$
* 如果我们设置了 $p_h=k_h-1$ 和 $p_w=k_w-1$，则输出形状将简化为 $\lfloor(n_h+s_h-1)/s_h\rfloor \times \lfloor(n_w+s_w-1)/s_w\rfloor$。更进一步，如果输入的高度和宽度可以被垂直和水平步幅整除，则输出形状将为 $(n_h/s_h) \times (n_w/s_w)$。
* 下面，我们[**将高度和宽度的步幅设置为2**]，从而将输入的高度和宽度减半。
    * 创建卷积层时，通过strides参数来设置步幅，只设置一个数是行列同一个步幅，用设置数对，可以使行列的采用不同的步幅。


```python
# 通过strids参数来设置参数
conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same', strides=2)
comp_conv2d(conv2d, X).shape
```




    TensorShape([4, 4])



* 下面设置行列不同的步幅：


```python
conv2d = tf.keras.layers.Conv2D(1, kernel_size=(3,5), padding='valid',
                                strides=(3, 4))
comp_conv2d(conv2d, X).shape
```




    TensorShape([2, 1])



* 为了简洁起见，当输入高度和宽度两侧的填充数量不同，分别为 $p_h$ 和 $p_w$ 时，我们称之为填充 $(p_h, p_w)$。当 $p_h = p_w = p$ 时，填充是 $p$。
* 同理，当高度和宽度上的步幅不同，分别为 $s_h$ 和 $s_w$ 时，我们称之为步幅 $(s_h, s_w)$。当步幅为 $s_h = s_w = s$ 时，步幅为 $s$。
* 默认情况下，填充为 0，步幅为 1。
* 在实践中，我们很少使用不一致的步幅或填充，也就是说，我们通常有 $p_h = p_w$ 和 $s_h = s_w$。

# 多输入多输出通道

* 每个图像的由多个通道和多层卷积层构成。例如彩色图像具有标准的 RGB 通道来指示红、绿和蓝。
* 前面为了简化理解，我们仅使用了单个输入和单个输出通道的简化例子。这使得我们可以将输入、卷积核和输出看作二维张量。
* 当我们添加通道时，我们的输入和隐藏的表示都变成了三维张量。例如，每个RGB输入图像具有 $3\times h\times w$ 的形状。我们将这个大小为 $3$ 的轴称为 *通道*（channel） 维度。

## 多输入通道

* 当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数目的卷积核，以便与输入数据进行互相关运算。假设输入的通道数为 $c_i$，那么卷积核的输入通道数也需要为 $c_i$ 。如果卷积核的窗口形状是 $k_h\times k_w$，那么当 $c_i=1$ 时，我们可以把卷积核看作形状为 $k_h\times k_w$ 的二维张量。
* 当 $c_i>1$ 时，我们卷积核的每个输入通道将包含形状为 $k_h\times k_w$ 的张量。将这些张量 $c_i$ 连结在一起可以得到形状为 $c_i\times k_h\times k_w$ 的卷积核。
    * 由于输入和卷积核都有 $c_i$ 个通道，我们可以对每个通道输入的二维张量和卷积核的二维张量进行互相关运算，再对通道求和（将 $c_i$ 的结果相加）得到二维张量。这是多通道输入和多输入通道卷积核之间进行二维互相关运算的结果。
* 在下图中，我们演示了一个具有两个输入通道的二维互相关运算的示例。阴影部分是第一个输出元素以及用于计算这个输出的输入和核张量元素：$(1\times1+2\times2+4\times3+5\times4)+(0\times0+1\times1+3\times2+4\times3)=56$。

![](https://zjpicture.oss-cn-beijing.aliyuncs.com/img/20211127204709.png)
* 下面，我们将(**实现一下多输入通道互相关运算**)。简而言之，我们所做的就是对每个通道执行互相关操作，然后将结果相加。

* [corr2d函数定义（卷积神经网络）](https://www.zestaken.top/post/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0)


```python
import tensorflow as tf
from d2l import tensorflow as d2l


def corr2d_multi_in(X, K):
    # 先遍历 “X” 和 “K” 的第0个维度（通道维度），再把它们加在一起
    return tf.reduce_sum([d2l.corr2d(x, k) for x, k in zip(X, K)], axis=0)
```

* 我们可以构造与上图中的值相对应的输入张量 `X` 和核张量 `K`，以验证互相关运算的输出。


```python
X = tf.constant([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],# 一个通道
               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]]) # 第二个通道
K = tf.constant([[[0.0, 1.0], [2.0, 3.0]], # 核的第一层
                 [[1.0, 2.0], [3.0, 4.0]]]) # 核的第二层

corr2d_multi_in(X, K)
```




    <tf.Tensor: shape=(2, 2), dtype=float32, numpy=
    array([[ 56.,  72.],
           [104., 120.]], dtype=float32)>



## 多输出通道

* 每一层有多个输出通道是至关重要的。在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。
* 我们可以将每个通道看作是对不同特征的响应。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。因此，多输出通道并不仅是学习多个单通道的检测器。
* 用 $c_i$ 和 $c_o$ 分别表示输入和输出通道的数目，并让 $k_h$ 和 $k_w$ 为卷积核的高度和宽度。为了获得多个通道的输出，我们可以为每个输出通道创建一个形状为 $c_i\times k_h\times k_w$ 的卷积核张量，这样卷积核的形状是 $c_o\times c_i\times k_h\times k_w$。在互相关运算中，*每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果*。
* 如下所示，我们实现一个[**计算多个通道的输出的互相关函数**]。(注：[tf.stack详细解析](https://www.w3cschool.cn/tensorflow_python/tensorflow_python-36hu2mm9.html))


```python
def corr2d_multi_in_out(X, K):
    # 迭代“K”的第0个维度（第0个维度的多层），每次都对输入“X”执行互相关运算。
    # 最后将所有结果都叠加在一起,每叠加一次，输出通道的维度就升高一维
    return tf.stack([corr2d_multi_in(X, k) for k in K], 0)
```

* 通过将核张量 `K` 与 `K+1` （ `K` 中每个元素加 $1$ ）和 `K+2` 连接起来，构造了一个具有$3$个输出通道的卷积核。


```python
K = tf.stack((K, K + 1, K + 2), 0)
K.shape
```




    TensorShape([3, 2, 2, 2])



* 下面，我们对输入张量 `X` 与卷积核张量 `K` 执行互相关运算。现在的输出包含 $3$ 个通道，第一个通道的结果与先前输入张量 `X` 和多输入单输出通道的结果一致。


```python
corr2d_multi_in_out(X, K)
```




    <tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=
    array([[[ 56.,  72.],
            [104., 120.]],
    
           [[ 76., 100.],
            [148., 172.]],
    
           [[ 96., 128.],
            [192., 224.]]], dtype=float32)>



## $1\times 1$ 卷积层

* $1\times 1$ 卷积，即 $k_h = k_w = 1$。因为使用了最小窗口，$1\times 1$ 卷积失去了卷积层的特有能力——在高度和宽度维度上，识别相邻元素间相互作用的能力。其实 $1\times 1$ 卷积的*唯一计算发生在通道*上。即对同一位置不同通道的元素进行运算产生输出。
* 下图展示了使用 $1\times 1$ 卷积核与 $3$ 个输入通道和 $2$ 个输出通道的互相关计算。
    * 这里输入和输出具有相同的高度和宽度，输出中的每个元素都是从输入图像中同一位置的元素的线性组合。
    * 我们可以将 $1\times 1$ 卷积层看作是在每个像素位置应用的全连接层，以 $c_i$ 个输入值转换为 $c_o$ 个输出值。
    * 因为这仍然是一个卷积层，所以跨像素的权重是一致的。
    * 同时，$1\times 1$ 卷积层需要的权重维度为 $c_o\times c_i$ ，再额外加上一个偏置。
    ![NRIxEg](https://zjpicture.oss-cn-beijing.aliyuncs.com/giteePic/picgo-master/uPic/NRIxEg.png)
* 下面，我们使用全连接层实现 $1 \times 1$ 卷积。请注意，我们需要对输入和输出的数据形状进行微调。


```python
def corr2d_multi_in_out_1x1(X, K):
    c_i, h, w = X.shape
    c_o = K.shape[0]
    X = tf.reshape(X, (c_i, h * w))
    K = tf.reshape(K, (c_o, c_i))
    # 全连接层中的矩阵乘法
    Y = tf.matmul(K, X)
    return tf.reshape(Y, (c_o, h, w))
```

* 当执行 $1\times 1$ 卷积运算时，上述函数相当于先前实现的互相关函数`corr2d_multi_in_out`。让我们用一些样本数据来验证这一点。


```python
X = tf.random.normal((3, 3, 3), 0, 1)
K = tf.random.normal((2, 3, 1, 1), 0, 1)
```


```python
Y1 = corr2d_multi_in_out_1x1(X, K)
Y2 = corr2d_multi_in_out(X, K)
assert float(tf.reduce_sum(tf.abs(Y1 - Y2))) < 1e-6
```
# 池化层

* 通常当我们处理图像时，我们希望逐渐降低隐藏表示的空间分辨率，聚集信息，这样随着我们在神经网络中层叠的上升，每个神经元对其敏感的感受野（输入）就越大。
* 而我们的机器学习任务通常会跟全局图像的问题有关（例如，“图像是否包含一只猫呢？”）， 所以我们最后一层的神经元应该对整个输入的全局敏感。通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表示的目标，同时将卷积图层的所有优势保留在中间层。
* 池化（pooling）层（又可以叫做汇聚层），它具有双重作用：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性。

## 最大池化层和平均池化层

* 与卷积层类似，汇聚层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动，为固定形状窗口（有时称为 *池化窗口*）遍历的每个位置计算一个输出。
* 然而，不同于卷积层中的输入与卷积核之间的互相关计算，池化层不包含参数。相反，池运算符是确定性的，我们通常计算池化窗口中*所有元素的最大值或平均值*。这些操作分别称为 *最大池化层* （maximum pooling）和 *平均池化层* （average pooling）。
* 与互相关运算符一样，池化窗口从输入张量的*左上角开始，从左到右、从上到下*的在输入张量内滑动。在池化窗口到达的每个位置，它计算该窗口中输入子张量的最大值或平均值，具体取决于是使用了最大汇聚层还是平均汇聚层。
    ![oGNlMP](https://zjpicture.oss-cn-beijing.aliyuncs.com/giteePic/picgo-master/uPic/oGNlMP.png)
* 上图中的输出张量的高度为 $2$，宽度为 $2$。这四个元素为每个池化窗口中的最大值：
    $$
    \max(0, 1, 3, 4)=4,\\
    \max(1, 2, 4, 5)=5,\\
    \max(3, 4, 6, 7)=7,\\
    \max(4, 5, 7, 8)=8.\\
    $$
    * 池化窗口形状为 $p \times q$ 的汇聚层称为 $p \times q$ 汇聚层，池化操作称为 $p \times q$ 池化。
* 对于对象边缘检测，现在我们将使用卷积层的输出作为 $2\times 2$ 最大池化的输入。
    * 设置卷积层输入为 `X`，汇聚层输出为 `Y`。
    * 无论 `X[i, j]` 和 `X[i, j + 1]` 的值是否不同，或 `X[i, j + 1]` 和 `X[i, j + 2]` 的值是否不同，汇聚层始终输出 `Y[i, j] = 1`。也就是说，使用 $2\times 2$ 最大汇聚层，即使在高度或宽度上移动一个元素，卷积层仍然可以识别到模式。
* 在下面的代码中的 `pool2d` 函数，我们(**实现汇聚层的正向传播**)。此功能类似于 `corr2d` 函数。然而，这里我们没有卷积核，输出为输入中每个区域的最大值或平均值。


```python
import tensorflow as tf


def pool2d(X, pool_size, mode='max'): # mode设置最大汇聚层模式和平均汇聚层模式
    p_h, p_w = pool_size
    Y = tf.Variable(tf.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w +1)))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            if mode == 'max':
                Y[i, j].assign(tf.reduce_max(X[i: i + p_h, j: j + p_w]))
            elif mode =='avg':
                Y[i, j].assign(tf.reduce_mean(X[i: i + p_h, j: j + p_w]))
    return Y
```

* 我们可以构建上图中的输入张量 `X`，[**验证二维最大汇聚层的输出**]。


```python
X = tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
pool2d(X, (2, 2))
```




    <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=
    array([[4., 5.],
           [7., 8.]], dtype=float32)>



* 此外，我们还可以(**验证平均汇聚层**)。


```python
pool2d(X, (2, 2), 'avg')
```




    <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=
    array([[2., 3.],
           [5., 6.]], dtype=float32)>



## 填充和步幅

* 与卷积层一样，汇聚层也可以*改变输出形状*。和以前一样，我们可以*通过填充和步幅以获得所需的输出形状*。下面，我们用深度学习框架中内置的二维最大汇聚层，来演示汇聚层中填充和步幅的使用。我们首先构造了一个输入张量 `X`，它有四个维度，其中样本数和通道数都是 1。


```python
X = tf.reshape(tf.range(16, dtype=tf.float32), (1, 4, 4, 1))
X
```




    <tf.Tensor: shape=(1, 4, 4, 1), dtype=float32, numpy=
    array([[[[ 0.],
             [ 1.],
             [ 2.],
             [ 3.]],
    
            [[ 4.],
             [ 5.],
             [ 6.],
             [ 7.]],
    
            [[ 8.],
             [ 9.],
             [10.],
             [11.]],
    
            [[12.],
             [13.],
             [14.],
             [15.]]]], dtype=float32)>



* 默认情况下，(**深度学习框架中的步幅与池化窗口的大小相同**)。因此，如果我们使用形状为 `(3, 3)` 的池化窗口，那么默认情况下，我们得到的步幅形状为 `(3, 3)`。


```python
pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3])
pool2d(X)
```




    <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[10.]]]], dtype=float32)>



* [**填充和步幅可以手动设定**]。依然是通过`padding`参数和`strides`参数来设置。


```python
pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3], padding='same',
                                   strides=2) 
pool2d(X)
```




    <tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=
    array([[[[10.],
             [11.]],
    
            [[14.],
             [15.]]]], dtype=float32)>



* 我们可以(**设定一个任意大小的矩形池化窗口，并分别设定填充和步幅的高度和宽度**)。


```python
pool2d = tf.keras.layers.MaxPool2D(pool_size=[2, 3], padding='same',
                                   strides=(2, 3))
pool2d(X)
```




    <tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=
    array([[[[ 5.],
             [ 7.]],
    
            [[13.],
             [15.]]]], dtype=float32)>



## 多个通道

* 在处理多通道输入数据时，[**汇聚层在每个输入通道上单独运算**]，而不是像卷积层一样在通道上对输入进行汇总。这意味着汇聚层的*输出通道数与输入通道数相同*。
* 下面，我们将在通道维度上连结张量 `X` 和 `X + 1`，以构建具有 2 个通道的输入。


```python
X = tf.reshape(tf.stack([X, X+1], 0), (1, 2, 4, 4))
```

* 如下所示，池化后输出通道的数量仍然是 2。


```python
pool2d = tf.keras.layers.MaxPool2D(3, padding='same', strides=2)
pool2d(X)
```




    <tf.Tensor: shape=(1, 1, 2, 4), dtype=float32, numpy=
    array([[[[ 9., 10., 11., 12.],
             [13., 14., 15., 16.]]]], dtype=float32)>


# 卷积神经网络（LeNet）

* 之前我们将 softmax 回归模型和多层感知机模型应用于 Fashion-MNIST 数据集中的服装图片上。为了能够应用 softmax 回归和多层感知机，我们首先将每个大小为 $28\times28$ 的图像展平为一个 784 固定长度的一维向量，然后用全连接层对其进行处理。
* 而我们通过卷积层的处理方法，我们可以在图像中保留空间结构。同时，用卷积层代替全连接层的另一个好处是：更简洁的模型所需的参数更少。
* **LeNet**：它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。
    * 这个模型是由 AT&T 贝尔实验室的研究员 Yann LeCun 在1989年提出的（并以其命名），目的是识别图像中的手写数字。
    * 当时， LeNet 取得了与支持向量机（support vector machines）性能相媲美的成果，成为监督学习的主流方法。
    * LeNet 被广泛用于自动取款机（ATM）机中，帮助识别处理支票的数字。

## LeNet

* 总体来看，如下图所示，(**LeNet（LeNet-5）由两个部分组成：**)
    * 卷积编码器：由两个卷积层组成;
    * 全连接层密集块：由三个全连接层组成。
    ![](https://zjpicture.oss-cn-beijing.aliyuncs.com/img/20211201122207.png)
* 每个卷积块中的基本单元是一个卷积层、一个 sigmoid 激活函数和平均汇聚层。请注意，虽然 ReLU 和最大汇聚层更有效，但它们在20世纪90年代还没有出现。
* 每个卷积层使用 $5\times 5$ 卷积核和一个 sigmoid 激活函数。
    * 这些层将输入映射到多个二维特征输出，通常同时增加通道的数量。
    * 第一卷积层有 6 个输出通道，而第二个卷积层有 16 个输出通道。
    * 每个 $2\times2$ 池操作（步骤2）通过空间下采样将维数减少 4 倍。卷积的输出形状由批量大小、通道数、高度、宽度决定。
* 为了将卷积块的输出传递给稠密块（全连接层组合而成），我们必须*在小批量中展平每个样本*。换言之，我们将这个四维输入转换成全连接层所期望的二维输入。
    * 这里的二维表示的第一个维度索引小批量中的样本，第二个维度给出每个样本的平面向量表示。
    * LeNet 的稠密块有三个全连接层，分别有 120、84 和 10 个输出。因为我们仍在执行分类，所以输出层的 10 维对应于最后输出结果的数量。
* 通过下面的 LeNet 代码，我们只需要实例化一个 `Sequential` 块并将需要的层连接在一起就可实现该模型。


```python
import tensorflow as tf
from d2l import tensorflow as d2l

def net():
    return tf.keras.models.Sequential([ # 顺序连接各层即可
        tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='sigmoid',
                               padding='same'), # 卷积层
        tf.keras.layers.AvgPool2D(pool_size=2, strides=2), # 平均池化层
        tf.keras.layers.Conv2D(filters=16, kernel_size=5,  # 卷积层
                               activation='sigmoid'),
        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),# 平均池化层
        tf.keras.layers.Flatten(), # 展平
        tf.keras.layers.Dense(120, activation='sigmoid'), # 全连接层
        tf.keras.layers.Dense(84, activation='sigmoid'),
        tf.keras.layers.Dense(10)])
```

* 我们对原始模型做了一点小改动，去掉了最后一层的高斯激活。除此之外，这个网络与最初的 LeNet-5 一致。
* 下面，我们将一个大小为 $28 \times 28$ 的单通道（黑白）图像通过 LeNet。 通过在每一层打印输出的形状，我们可以[**检查模型**]，以确保其操作与我们期望的下图一致。
    ![](https://zjpicture.oss-cn-beijing.aliyuncs.com/img/20211201123101.png)


```python
X = tf.random.uniform((1, 28, 28, 1))
for layer in net().layers: # 以此将输入X通过模型的每一层处理并打印该层数据形状
    X = layer(X)
    print(layer.__class__.__name__, 'output shape: \t', X.shape)
```

    Conv2D output shape: 	 (1, 28, 28, 6)
    AveragePooling2D output shape: 	 (1, 14, 14, 6)
    Conv2D output shape: 	 (1, 10, 10, 16)
    AveragePooling2D output shape: 	 (1, 5, 5, 16)
    Flatten output shape: 	 (1, 400)
    Dense output shape: 	 (1, 120)
    Dense output shape: 	 (1, 84)
    Dense output shape: 	 (1, 10)
    

* 在整个卷积块中，与上一层相比，每一层特征的高度和宽度都减小了。
* 第一个卷积层使用 2 个像素的填充，来补偿 $5 \times 5$ 卷积核导致的特征减少。
* 相反，第二个卷积层没有填充，因此高度和宽度都减少了 4 个像素。
* 随着层叠的上升，通道的数量从输入时的 1 个，增加到第一个卷积层之后的 6 个，再到第二个卷积层之后的 16 个。
* 同时，每个汇聚层的高度和宽度都减半。最后，每个全连接层减少维数，最终输出一个维数与结果分类数相匹配的输出。

## 模型训练

* 现在我们已经实现了 LeNet ，让我们看看[**LeNet在Fashion-MNIST数据集上的表现**]。
* 注：[d2l定义的数据导入函数](https://www.zestaken.top/post/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0)


```python
batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)
```

* 虽然卷积神经网络的参数较少，但与深度的多层感知机相比，它们的计算成本仍然很高，因为每个参数都参与更多的乘法。如果能使用GPU，可以用它加快训练。

* 为了使用 GPU, 在进行正向和反向传播之前，我们需要将每一小批量数据移动到我们指定的设备（例如 GPU）上。如下所示，训练函数 `train_ch6` 也类似于之前定义的 `train_ch3` 。
* 由于我们将实现多层神经网络，因此我们将主要使用高级 API。以下训练函数假定从高级 API 创建的模型作为输入，并进行相应的优化。
* 我们使用 Xavier 随机初始化模型参数。
* 与全连接层一样，我们使用交叉熵损失函数和小批量随机梯度下降。


```python
class TrainCallback(tf.keras.callbacks.Callback):  #@save
    """一个以可视化的训练进展的回调。"""
    def __init__(self, net, train_iter, test_iter, num_epochs, device_name):
        self.timer = d2l.Timer()
        self.animator = d2l.Animator(
            xlabel='epoch', xlim=[1, num_epochs], legend=[
                'train loss', 'train acc', 'test acc'])
        self.net = net
        self.train_iter = train_iter
        self.test_iter = test_iter
        self.num_epochs = num_epochs
        self.device_name = device_name
    def on_epoch_begin(self, epoch, logs=None):
        self.timer.start()
    def on_epoch_end(self, epoch, logs):
        self.timer.stop()
        test_acc = self.net.evaluate(
            self.test_iter, verbose=0, return_dict=True)['accuracy']
        metrics = (logs['loss'], logs['accuracy'], test_acc)
        self.animator.add(epoch + 1, metrics)
        if epoch == self.num_epochs - 1:
            batch_size = next(iter(self.train_iter))[0].shape[0]
            num_examples = batch_size * tf.data.experimental.cardinality(
                self.train_iter).numpy()
            print(f'loss {metrics[0]:.3f}, train acc {metrics[1]:.3f}, '
                  f'test acc {metrics[2]:.3f}')
            print(f'{num_examples / self.timer.avg():.1f} examples/sec on '
                  f'{str(self.device_name)}')

#@save
def train_ch6(net_fn, train_iter, test_iter, num_epochs, lr, device):
    """用GPU训练模型"""
    device_name = device._device_name # 获取设备
     # 使用框架的分布式策略使用GPU
    strategy = tf.distribute.OneDeviceStrategy(device_name)
    with strategy.scope():
        optimizer = tf.keras.optimizers.SGD(learning_rate=lr) # 优化器
        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
        net = net_fn()
        net.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])
    callback = TrainCallback(net, train_iter, test_iter, num_epochs,
                             device_name) # 绘图
    net.fit(train_iter, epochs=num_epochs, verbose=0, callbacks=[callback])
    return net
```

* 现在，我们[**训练和评估LeNet-5模型**]。注：[GPU相关函数](https://www.zestaken.top/post/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0)


```python
lr, num_epochs = 0.9, 10
train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```

    loss 0.484, train acc 0.816, test acc 0.813
    60806.8 examples/sec on /GPU:0
    

    <tensorflow.python.keras.engine.sequential.Sequential at 0x2b96668c220>




    
![](https://zjpicture.oss-cn-beijing.aliyuncs.com/img/20211201143720.svg)
    


* 附上用CPU训练的结果，与用一个GPU训练的速度足有20余倍之差。
![3K75Ff](https://zjpicture.oss-cn-beijing.aliyuncs.com/giteePic/picgo-master/uPic/3K75Ff.png)


