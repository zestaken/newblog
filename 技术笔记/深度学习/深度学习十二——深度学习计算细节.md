---
title: 深度学习十二——深度学习计算细节
date: 2021-11-27 12:02:19
tags: [深度学习]
categories: 技术笔记
mathjax: true
---
# 层和块

* 单一输出的线性模型。在这里，整个模型只由一个神经元组成。单个神经元
    1. 接受一些输入；
    2. 生成相应的标量输出；
    3. 具有一组相关 *参数*（parameters），这些参数可以更新以优化目标函数。
* 具有多个输出的网络，我们就利用矢量化算法来描述整层神经元。像单个神经元一样，层接受一组输入，生成相应的输出，由一组可调整参数描述。当我们使用softmax回归时，一个单层本身就是模型。
* 对于多层感知机而言，整个模型及其组成层都是这种结构。整个模型接受原始输入（特征），生成输出（预测），并包含一些参数（所有组成层的参数集合）。同样，每个单独的层接收输入（由前一层提供）生成输出（到下一层的输入），并且具有一组可调参数，这些参数根据从下一层反向传播的信号进行更新。
* 神经网络*块*的概念。
    * 块可以描述单个层、由多个层组成的组件或整个模型本身。
    * 块抽象的一个主要优点是它的多功能性。我们可以子类化块以创建层（如全连接层的类）、整个模型（如上面的`MLP`类）或具有中等复杂度的各种组件。
    * 使用块进行抽象的一个好处是可以将一些块组合成更大的组件，这一过程通常是递归的。多个层被组合成块，形成更大的模型如下图所示：
    ![](https://zjpicture.oss-cn-beijing.aliyuncs.com/img/20211125110915.png)
* 从编程的角度来看，块由*类*（class）表示。
    * 它的任何子类都必须定义一个将其输入转换为输出的正向传播函数，并且必须存储所有必需的参数。注意，有些块不需要任何参数。
    * 为了计算梯度，块必须具有反向传播函数。由于自动微分提供了一些后端实现，我们只需要考虑正向传播函数和必需的参数。
* 总的来说，层、块和模型的概念的意思相同，只是概念的意义大小不同。可以说层也是块，块也是模型。

## 层的实现

* 下面的代码生成一个网络，其中包含一个具有256个单元和ReLU激活函数的全连接的*隐藏层*，然后是一个具有10个隐藏单元且不带激活函数的全连接的*输出层*。


```python
import tensorflow as tf

net = tf.keras.models.Sequential([
    tf.keras.layers.Dense(256, activation=tf.nn.relu), # 全连接隐藏层
    tf.keras.layers.Dense(10), # 全连接输出层
])
X = tf.random.uniform((2, 20)) # 随机生成固定范围的数字，并组成2x20的矩阵
net(X) #将矩阵传入模型，得到输出
```




    <tf.Tensor: shape=(2, 10), dtype=float32, numpy=
    array([[-0.10053267, -0.52125233,  0.03423303,  0.05271533,  0.09385592,
             0.3140592 ,  0.48896453,  0.16119169,  0.2954839 ,  0.23833668],
           [-0.10363767, -0.360658  ,  0.08614046, -0.06917804,  0.15384349,
             0.16218697,  0.49132586,  0.0954482 ,  0.19657846,  0.0928633 ]],
          dtype=float32)>



* 在这个例子中，我们通过实例化`keras.models.Sequential`来构建我们的模型，层的执行顺序是作为参数传递的（即在定义时的顺序）。
* `Sequential`定义了一种特殊的`keras.Model`，即在Keras中表示一个块的类。它维护了一个由`Model`组成的有序列表，注意两个全连接层都是`Model`类的实例，这个类本身就是`Model`的子类。
* 正向传播（`call`）函数也非常简单：它将列表中的每个块连接在一起，将每个块的输出作为下一个块的输入。
* 注意，到目前为止，我们一直在通过`net(X)`调用我们的模型来获得模型的输出。这实际上是`net.call(X)`的简写，这是通过Block类的`__call__`函数实现的一个Python技巧。

## 自定义实现块

* 每个块必须提供的基本功能：
    1. 将*输入*数据作为其正向传播函数的参数。
    2. 通过正向传播函数来生成*输出*。请注意，输出的形状可能与输入的形状不同。例如，我们上面模型中的第一个全连接的层接收任意维的输入，但是返回一个维度256的输出。
    3. 计算其输出关于输入的*梯度*，可通过其反向传播函数进行访问。通常这是自动发生的。
    4. 存储和访问正向传播计算所需的*参数*。
    5. 根据需要*初始化模型参数*。
* 在下面的代码片段中，我们从零开始编写一个块。
    * 它包含一个多层感知机，其具有256个隐藏单元的隐藏层和一个10维输出层。
    * 注意，下面的`MLP`类继承了表示块的类。我们的实现将严重依赖父类，只需要提供我们自己的构造函数（Python中的`__init__`函数）和正向传播函数。


```python
class MLP(tf.keras.Model): # MLP继承自tf.keras.Model类（所有表示块的类的父类）
    # 用模型参数声明层。这里，我们声明两个全连接的层
    def __init__(self):
        # 调用`MLP`的父类`Block`的构造函数来执行必要的初始化。
        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数`params`（稍后将介绍）
        super().__init__()
        # Hidden layer
        self.hidden = tf.keras.layers.Dense(units=256, activation=tf.nn.relu) # 定义块的隐藏层属性
        self.out = tf.keras.layers.Dense(units=10)  # Output layer 定义块的输出层属性

    # 定义模型的正向传播，即如何根据输入`X`返回所需的模型输出
    def call(self, X):
        return self.out(self.hidden((X))) # 层的传播顺序
```

* 我们在构造函数中实例化多层感知机的层，然后在每次调用正向传播函数时调用这些层。
* 首先，我们定制的`__init__`函数通过`super().__init__()`调用父类的`__init__`函数，省去了重复编写适用于大多数块的模版代码的痛苦。
* 然后我们实例化两个全连接层，分别为`self.hidden`和`self.out`。
* 注意，除非我们实现一个新的运算符，否则我们*不必担心反向传播函数或参数初始化，系统将自动生成这些*。
* 如下代码尝试使用我们自定义块生成的模型。


```python
net = MLP()
net(X) # 不用设置初始化参数，框架会帮我们完成
```




    <tf.Tensor: shape=(2, 10), dtype=float32, numpy=
    array([[ 0.1348275 ,  0.02004568,  0.159919  , -0.14136608,  0.2755974 ,
             0.2720098 , -0.02464058, -0.1562115 ,  0.16649963,  0.26428697],
           [ 0.22408512,  0.18740931,  0.24371581, -0.01962556,  0.20510244,
             0.10686708,  0.04737062, -0.20873724,  0.19347262,  0.24820918]],
          dtype=float32)>



## 顺序块(Sequential)

* 现在我们可以更仔细地看看`Sequential`类是如何工作的。回想一下`Sequential`的设计是为了把其他模块串起来。为了构建我们自己的简化的`MySequential`，我们只需要定义两个关键函数：
    1. 一种将块逐个追加到列表中的函数。
    2. 一种正向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”。
* 下面的`MySequential`类提供了与默认`Sequential`类相同的功能。


```python
class MySequential(tf.keras.Model):
    def __init__(self, *args):
        super().__init__()
        self.modules = [] # 存储多个层/块
        for block in args:
            # 这里，`block`是`tf.keras.layers.Layer`子类的一个实例。
            self.modules.append(block) # 将输入的层/块添加存储

    def call(self, X):
        for module in self.modules:
            X = module(X) # 按添加顺序调用存储的层/块
        return X
```

* 当`MySequential`的正向传播函数被调用时，每个添加的块都按照它们被添加的顺序执行。现在可以使用我们的`MySequential`类重新实现多层感知机。
* `MySequential`的用法与之前为`Sequential`类编写的代码相同。


```python
net = MySequential(
    tf.keras.layers.Dense(units=256, activation=tf.nn.relu),
    tf.keras.layers.Dense(10))
net(X)
```




    <tf.Tensor: shape=(2, 10), dtype=float32, numpy=
    array([[-0.3732779 ,  0.13598867,  0.06229738, -0.14902727,  0.29809335,
            -0.17750566, -0.04478821,  0.28876683,  0.36625353, -0.07922162],
           [-0.13440742,  0.15157597, -0.04832599, -0.09506966,  0.11088407,
            -0.2799356 , -0.09352981,  0.16300732,  0.3455552 ,  0.11073787]],
          dtype=float32)>



## 在正向传播函数中执行代码

* `Sequential`类使模型构造变得简单，允许我们组合新的结构，而不必定义自己的类。然而，并不是所有的架构都是简单的顺序结构。当需要更大的灵活性时，我们需要定义自己的块。例如，我们可能希望在正向传播函数中执行Python的控制流。此外，我们可能希望执行任意的数学运算，而不是简单地依赖预定义的神经网络层。
* 到目前为止，我们网络中的所有操作都对网络的激活值及网络的参数起作用。然而，有时我们可能希望合并既不是上一层的结果也不是可更新参数的项。我们称之为常数参数（constant parameters）。
    * 例如，我们需要一个计算函数$f(\mathbf{x},\mathbf{w}) = c \cdot \mathbf{w}^\top \mathbf{x}$的层，其中$\mathbf{x}$是输入，$\mathbf{w}$是我们的参数，$c$是某个在优化过程中没有更新的指定常量。因此我们实现了一个`FixedHiddenMLP`类，如下所示：


```python
class FixedHiddenMLP(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.flatten = tf.keras.layers.Flatten() # Flatten层用来将输入“压平”，即把多维的输入一维化。
        # 使用`tf.constant`函数创建的随机权重参数在训练期间不会更新（即为常量参数）。
        self.rand_weight = tf.constant(tf.random.uniform((20, 20)))
        self.dense = tf.keras.layers.Dense(20, activation=tf.nn.relu) # 全连接层

    def call(self, inputs):
        X = self.flatten(inputs)
        # 使用创建的常量参数以及`relu`和`matmul`函数。
        X = tf.nn.relu(tf.matmul(X, self.rand_weight) + 1) # 对输入值进行运算转换
        # 复用全连接层。这相当于两个全连接层共享参数。
        X = self.dense(X)
        # 控制流
        while tf.reduce_sum(tf.math.abs(X)) > 1:
            X /= 2
        return tf.reduce_sum(X)
```

* 在这个`FixedHiddenMLP`模型中，我们实现了一个隐藏层，其权重（`self.rand_weight`）在实例化时被随机初始化，之后为常量。这个权重不是一个模型参数，因此它永远不会被反向传播更新。然后，网络将这个固定层的输出通过一个全连接层。
* 在返回输出之前，我们的模型运行了一个while循环，在$L_1$范数大于$1$的条件下，将输出向量除以$2$，直到它满足条件为止。最后，我们返回了`X`中所有项的和。据我们所知，没有标准的神经网络执行这种操作。注意，此特定操作在任何实际任务中可能都没有用处，只是展示如何将任意代码集成到神经网络计算的流程中。


```python
net = FixedHiddenMLP()
net(X)
```




    <tf.Tensor: shape=(), dtype=float32, numpy=0.6047544>



* 我们可以[**混合搭配各种组合块的方法**]。在下面的例子中，我们以一些想到的方法嵌套块。


```python
class NestMLP(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.net = tf.keras.Sequential()
        self.net.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))
        self.net.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))
        self.dense = tf.keras.layers.Dense(16, activation=tf.nn.relu)

    def call(self, inputs):
        return self.dense(self.net(inputs))

chimera = tf.keras.Sequential()
chimera.add(NestMLP())
chimera.add(tf.keras.layers.Dense(20))
chimera.add(FixedHiddenMLP())
chimera(X)
```




    <tf.Tensor: shape=(), dtype=float32, numpy=0.96118724>


# 参数管理

* 一旦我们选择了架构并设置了超参数，我们就进入了训练阶段。我们的目标是找到使损失函数最小化的参数值。
    * 经过训练后，我们将需要使用这些参数来做出未来的预测。
    * 此外，有时我们希望提取参数，以便在其他环境中复用它们，将模型保存到磁盘，以便它可以在其他软件中执行，或者为了获得科学的理解而进行检查。
* 接下来将介绍参数使用的三个方面：
    * 访问参数，用于调试、诊断和可视化。
    * 参数初始化。
    * 在不同模型组件间共享参数。
* 我们首先定义一个具有单隐藏层的多层感知机。


```python
import tensorflow as tf

net = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(), # Flatten层用来将输入“压平”，即把多维的输入一维化。
    tf.keras.layers.Dense(4, activation=tf.nn.relu),
    tf.keras.layers.Dense(1),
])

X = tf.random.uniform((2, 4))
net(X)
```




    <tf.Tensor: shape=(2, 1), dtype=float32, numpy=
    array([[1.0823346 ],
           [0.22759864]], dtype=float32)>



## 参数访问

* 我们从已有模型中访问参数。当通过`Sequential`类定义模型时，我们可以通过索引来访问模型的任意层。这就像模型是一个列表一样。每层的参数都在其属性中。如下所示，我们可以检查第二个全连接层的参数：


```python
print(net.layers[2].weights)
```

    [<tf.Variable 'dense_1/kernel:0' shape=(4, 1) dtype=float32, numpy=
    array([[-1.0443994 ],
           [ 0.9794688 ],
           [-0.9471145 ],
           [ 0.72745836]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]
    

* 输出的结果告诉我们一些重要的事情：
    * 首先，这个全连接层包含两个参数，分别是该层的权重和偏置。两者都存储为单精度浮点数（float32）。
    * 其次，权重参数有4个，偏置参数有1个

### 访问目标参数

* 注意，每个参数都表示为参数（parameter）类的一个实例。要对参数执行任何操作，首先我们需要访问底层的数值。
* 下面的代码从第二个神经网络层提取偏置，提取后返回的是一个参数类实例，并进一步访问该参数的值。


```python
print(type(net.layers[2].weights[1]))
print(net.layers[2].weights[1])
print(tf.convert_to_tensor(net.layers[2].weights[1]))
```

    <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>
    <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>
    tf.Tensor([0.], shape=(1,), dtype=float32)
    

### 一次性访问所有参数

* 当我们需要对所有参数执行操作时，逐个访问它们可能会很麻烦。
* 下面，我们将通过演示来比较访问第一个全连接层的参数和访问所有层。


```python
print(net.layers[1].weights)
print("-------------------")
print(net.get_weights())
```

    [<tf.Variable 'dense/kernel:0' shape=(4, 4) dtype=float32, numpy=
    array([[-0.7153008 , -0.47379696,  0.24041837, -0.47431007],
           [-0.27177972,  0.8531895 ,  0.81762785,  0.09699482],
           [ 0.5649834 , -0.11347246, -0.760539  ,  0.643614  ],
           [ 0.38823944,  0.85819894, -0.51748407, -0.8652288 ]],
          dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]
    -------------------
    [array([[-0.7153008 , -0.47379696,  0.24041837, -0.47431007],
           [-0.27177972,  0.8531895 ,  0.81762785,  0.09699482],
           [ 0.5649834 , -0.11347246, -0.760539  ,  0.643614  ],
           [ 0.38823944,  0.85819894, -0.51748407, -0.8652288 ]],
          dtype=float32), array([0., 0., 0., 0.], dtype=float32), array([[-1.0443994 ],
           [ 0.9794688 ],
           [-0.9471145 ],
           [ 0.72745836]], dtype=float32), array([0.], dtype=float32)]
    

* 这为我们提供了另一种访问网络参数的方式，如下所示。


```python
net.get_weights()[1]
```




    array([0., 0., 0., 0.], dtype=float32)



### 从嵌套块收集参数

* 如果我们将多个块相互嵌套，参数命名约定是如何工作的。为此，我们首先定义一个生成块的函数（可以说是块工厂），然后将这些块组合到更大的块中。


```python
def block1(name):
    return tf.keras.Sequential([
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(4, activation=tf.nn.relu)],
        name=name)

def block2():
    net = tf.keras.Sequential()
    for i in range(4):
        # 在这里嵌套
        net.add(block1(name=f'block-{i}'))
    return net

rgnet = tf.keras.Sequential()
rgnet.add(block2())
rgnet.add(tf.keras.layers.Dense(1))
rgnet(X)
```




    <tf.Tensor: shape=(2, 1), dtype=float32, numpy=
    array([[0.29514068],
           [0.24460116]], dtype=float32)>



* 现在我们已经设计了网络，让我们看看它是如何组织的。


```python
print(rgnet.summary())
```

    Model: "sequential_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    sequential_2 (Sequential)    (2, 4)                    80        
    _________________________________________________________________
    dense_6 (Dense)              (2, 1)                    5         
    =================================================================
    Total params: 85
    Trainable params: 85
    Non-trainable params: 0
    _________________________________________________________________
    None
    

* 因为层是分层嵌套的，所以我们也可以像通过嵌套列表索引一样访问它们。例如，我们下面访问第一个主要的块，其中第二个子块的第一层的偏置项。


```python
rgnet.layers[0].layers[1].layers[1].weights[1]
```




    <tf.Variable 'dense_3/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>



## 参数初始化

* 深度学习框架提供默认随机初始化。然而，我们经常希望根据其他规则初始化权重。
* 深度学习框架提供了最常用的规则，也允许创建自定义初始化方法。

* 默认情况下，Keras会根据一个范围均匀地初始化权重矩阵，这个范围是根据输入和输出维度计算出的。偏置参数设置为0。
* TensorFlow在根模块和`keras.initializers`模块中提供了各种初始化方法。

### 内置初始化

* 让我们首先调用内置的初始化器。下面的代码将所有权重参数初始化为标准差为0.01的高斯随机变量，且将偏置参数设置为0。


```python
net = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(
        4, activation=tf.nn.relu,
        # 调用内置的权重和偏置初始化器
        kernel_initializer=tf.random_normal_initializer(mean=0, stddev=0.01), 
        bias_initializer=tf.zeros_initializer()),
    tf.keras.layers.Dense(1)])

net(X)
net.weights[0], net.weights[1]
```




    (<tf.Variable 'dense_7/kernel:0' shape=(4, 4) dtype=float32, numpy=
     array([[ 0.00011626, -0.00243756,  0.0289169 ,  0.01210678],
            [-0.0209518 , -0.00309604,  0.00333905,  0.00578496],
            [ 0.00712939,  0.00440856,  0.01441487, -0.01851764],
            [ 0.00087012,  0.00539779, -0.01484406,  0.00173946]],
           dtype=float32)>,
     <tf.Variable 'dense_7/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>)



* 我们还可以将所有参数初始化为给定的常数（比如1）。


```python
net = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(
        4, activation=tf.nn.relu,
        kernel_initializer=tf.keras.initializers.Constant(1), # 权重参数初始化为常数1
        bias_initializer=tf.zeros_initializer()),
    tf.keras.layers.Dense(1),
])

net(X)
net.weights[0], net.weights[1]
```




    (<tf.Variable 'dense_9/kernel:0' shape=(4, 4) dtype=float32, numpy=
     array([[1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.],
            [1., 1., 1., 1.]], dtype=float32)>,
     <tf.Variable 'dense_9/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>)



* 我们还可以对不同块应用不同的初始化方法。例如，下面我们使用[Xavier初始化方法](https://www.zestaken.top/post/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%9D%E2%80%94%E2%80%94%E6%95%B0%E5%80%BC%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%88%9D%E5%A7%8B%E5%8C%96)初始化第一层，然后第二层初始化为常量值42。


```python
net = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(
        4,
        activation=tf.nn.relu,
        kernel_initializer=tf.keras.initializers.GlorotUniform()),
    tf.keras.layers.Dense(
        1, kernel_initializer=tf.keras.initializers.Constant(1)),
])

net(X)
print(net.layers[1].weights[0])
print(net.layers[2].weights[0])
```

    <tf.Variable 'dense_11/kernel:0' shape=(4, 4) dtype=float32, numpy=
    array([[ 0.13322777, -0.28714836,  0.48435372, -0.23824066],
           [-0.8576961 , -0.37366742, -0.5298128 , -0.57621306],
           [ 0.15267748, -0.55146253,  0.2456879 ,  0.8000147 ],
           [-0.84722054,  0.26036924,  0.14320487,  0.2029993 ]],
          dtype=float32)>
    <tf.Variable 'dense_12/kernel:0' shape=(4, 1) dtype=float32, numpy=
    array([[1.],
           [1.],
           [1.],
           [1.]], dtype=float32)>
    

### 自定义初始化

* 当深度学习框架没有提供我们需要的初始化方法,这时就需要自己去定义初始化方法。
* 在下面的例子中，我们使用以下的分布为任意权重参数$w$定义初始化方法：
$$
\begin{aligned}
    w \sim \begin{cases}
        U(5, 10) & \text{ with probability } \frac{1}{4} \\
            0    & \text{ with probability } \frac{1}{2} \\
        U(-10, -5) & \text{ with probability } \frac{1}{4}
    \end{cases}
\end{aligned}
$$

* 下面我们定义了一个`Initializer`的子类，并实现了`__call__`函数。该函数返回给定形状和数据类型的所需张量（即返回指定类型的参数）。


```python
class MyInit(tf.keras.initializers.Initializer): # 需要继承
    def __call__(self, shape, dtype=None):
        data=tf.random.uniform(shape, -10, 10, dtype=dtype)
        factor=(tf.abs(data) >= 5)
        factor=tf.cast(factor, tf.float32)
        return data * factor

net = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(
        4,
        activation=tf.nn.relu,
        kernel_initializer=MyInit()),
    tf.keras.layers.Dense(1),
])

net(X)
print(net.layers[1].weights[0])
```

    <tf.Variable 'dense_13/kernel:0' shape=(4, 4) dtype=float32, numpy=
    array([[ 5.3779716, -0.       , -0.       , -0.       ],
           [ 9.236822 ,  5.445669 ,  6.13076  ,  0.       ],
           [ 0.       , -7.9621553, -6.879289 ,  0.       ],
           [ 7.567747 , -9.157478 , -9.440246 , -0.       ]], dtype=float32)>
    

* 此外，我们始终可以直接设置参数。


```python
net.layers[1].weights[0][:].assign(net.layers[1].weights[0] + 1)
net.layers[1].weights[0][0, 0].assign(42)
net.layers[1].weights[0]
```




    <tf.Variable 'dense_13/kernel:0' shape=(4, 4) dtype=float32, numpy=
    array([[42.       ,  1.       ,  1.       ,  1.       ],
           [10.236822 ,  6.445669 ,  7.13076  ,  1.       ],
           [ 1.       , -6.9621553, -5.879289 ,  1.       ],
           [ 8.567747 , -8.157478 , -8.440246 ,  1.       ]], dtype=float32)>



## 参数绑定

* 有时我们希望*在多个层间共享参数*。让我们看看如何优雅地做这件事。
* 在下面，我们定义一个稠密层，然后*使用它的参数来设置另一个层的参数*。


```python
# tf.keras的表现有点不同。它会自动删除重复层
shared = tf.keras.layers.Dense(4, activation=tf.nn.relu)
net = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    shared,
    shared,
    tf.keras.layers.Dense(1),
])

net(X)
# 检查参数是否不同
print(len(net.layers) == 3)
```

    True
    
# 延后初始化

* 到目前为止，似乎我们在建立网络时表现得很简单。我们没有做以下必要的工作，却能够建立可运行的网络：
    * 我们定义了网络架构，但没有指定输入维度。
    * 我们添加层时没有指定前一层的输出维度。
    * 我们在初始化参数时，甚至没有足够的信息来确定模型应该包含多少参数。
* 深度学习框架无法判断网络的输入维度是什么。但是框架通过**延后初始化（defers initialization）**来解决这个问题，即等到我们第一次将数据通过模型传递时，才会*动态地推断*出每个层的大小。

## 实例化网络

* 首先，让我们实例化一个多层感知机。


```python
import tensorflow as tf

net = tf.keras.models.Sequential([
    tf.keras.layers.Dense(256, activation=tf.nn.relu),
    tf.keras.layers.Dense(10),
])
```

* 此时，因为输入维数是未知的，所以网络不可能知道输入层权重的维数。因此，*框架尚未初始化任何参数*。我们通过尝试访问以下参数进行确认。


```python
[net.layers[i].get_weights() for i in range(len(net.layers))]
```




    [[], []]



* 请注意，每个层对象都存在，但权重为空。使用`net.get_weights()`将抛出一个错误，因为权重尚未初始化。

* 接下来让我们将数据通过网络，最终使框架初始化参数。


```python
X = tf.random.uniform((2, 20))
net(X)
[w.shape for w in net.get_weights()]
```




    [(20, 256), (256,), (256, 10), (10,)]



* 一旦我们知道输入维数是20，框架可以通过代入值20来识别第一层权重矩阵的形状。识别出第一层的形状后，框架处理第二层，依此类推，直到所有形状都已知为止。注意，在这种情况下，只有第一层需要延迟初始化，但是框架仍是按顺序初始化的。等到知道了所有的参数形状，框架就可以初始化参数。

# 自定义层

* 深度学习成功背后的一个因素是，可以用创造性的方式组合广泛的层，从而设计出适用于各种任务的结构。例如，研究人员发明了专门用于处理图像、文本、序列数据和执行动态编程的层。早晚有一天，你会遇到或要自己发明一个在深度学习框架中还不存在的层。在这些情况下，你必须构建自定义层。

## 不带参数的层

* 首先，我们(**构造一个没有任何参数的自定义层**)。下面的`CenteredLayer`类要从其输入中减去均值。要构建它，我们只需继承基础层类并实现正向传播功能。


```python
import tensorflow as tf


class CenteredLayer(tf.keras.Model): # 要继承Model类（层，块，模型同义）
    def __init__(self):
        super().__init__()

    def call(self, inputs):
        return inputs - tf.reduce_mean(inputs)
```

* 让我们通过向其提供一些数据来验证该层是否按预期工作。


```python
layer = CenteredLayer()
layer(tf.constant([1, 2, 3, 4, 5]))
```




    <tf.Tensor: shape=(5,), dtype=int32, numpy=array([-2, -1,  0,  1,  2])>



* 我们可以将层作为组件合并到构建更复杂的模型中。


```python
net = tf.keras.Sequential([tf.keras.layers.Dense(128), CenteredLayer()])
```

* 作为额外的健全性检查，我们可以向网络发送随机数据后，检查均值是否为0。由于我们处理的是浮点数，因为存储精度的原因，我们仍然可能会看到一个非常小的非零数。


```python
Y = net(tf.random.uniform((4, 8)))
tf.reduce_mean(Y)# 在自定义层中所有数已经减去了均值，此时再求他们的均值就为0
```




    <tf.Tensor: shape=(), dtype=float32, numpy=2.3283064e-10>



## 带参数的层

* 在知道如何定义简单的层后，让我们继续定义具有参数的层，这些参数可以通过训练进行调整。
* 我们可以使用内置函数来创建参数，这些函数提供一些基本的管理功能。比如管理访问、初始化、共享、保存和加载模型参数。这样做的好处之一是，我们不需要为每个自定义层编写自定义序列化程序。
* 下面实现*自定义版本的全连接层*。该层需要两个参数，一个用于表示权重，另一个用于表示偏置项。在此实现中，我们使用ReLU作为激活函数。该层需要输入参数：`in_units`和`units`，分别表示输入和输出的数量。


```python
class MyDense(tf.keras.Model): # 继承
    def __init__(self, units):
        super().__init__()
        self.units = units # 激活函数的参数：输出的数量

    # 通过继承的add_weight函数设置参数
    # weight和bias参数也是继承而来的
    def build(self, X_shape):
        self.weight = self.add_weight(name='weight',
            shape=[X_shape[-1], self.units],# 定义形状
            initializer=tf.random_normal_initializer()) # 权重参数的设置
        self.bias = self.add_weight(
            name='bias', shape=[self.units], 
            initializer=tf.zeros_initializer()) # 偏置参数的设置

    def call(self, X):
        linear = tf.matmul(X, self.weight) + self.bias # 线性模型的计算式，模型的核心
        return tf.nn.relu(linear) # 返回通过激活函数转换的结果
```

* 接下来，我们实例化`MyDense`类并访问其模型参数。


```python
dense = MyDense(3)
dense(tf.random.uniform((2, 5)))
dense.get_weights()
```




    [array([[ 0.06708992,  0.00083597,  0.02334282],
            [-0.03166975, -0.03228635,  0.0486607 ],
            [ 0.01708961,  0.04761021,  0.04423346],
            [-0.00652742, -0.04853096,  0.0032647 ],
            [ 0.07011791, -0.06639327, -0.07551213]], dtype=float32),
     array([0., 0., 0.], dtype=float32)]



* 我们可以[**使用自定义层直接执行正向传播计算**]。


```python
dense(tf.random.uniform((2, 5)))
```




    <tf.Tensor: shape=(2, 3), dtype=float32, numpy=
    array([[0.07556991, 0.        , 0.        ],
           [0.03051041, 0.        , 0.04300407]], dtype=float32)>



* 我们还可以(**使用自定义层构建模型**)。我们可以像使用内置的全连接层一样使用自定义层。


```python
net = tf.keras.models.Sequential([MyDense(8), MyDense(1)])
net(tf.random.uniform((2, 64)))
```




    <tf.Tensor: shape=(2, 1), dtype=float32, numpy=
    array([[0.04842976],
           [0.02571042]], dtype=float32)>


# 读写文件

* 有时我们对所学的模型足够满意，我们希望保存训练的模型以备将来在各种环境中使用（甚至可能在部署中进行预测）。此外，当运行一个耗时较长的训练过程时，最佳的做法是定期保存中间结果（检查点），以确保在服务器电源被不小心断掉时不会损失几天的计算结果。因此，我们需要学习如何加载和存储权重向量和整个模型。

## 加载和保存张量

* 对于单个张量，我们可以直接调用`load`和`save`函数分别读写它们。这两个函数都要求我们提供一个名称，`save`要求将要保存的变量作为输入。


```python
import numpy as np
import tensorflow as tf

x = tf.range(4)
np.save('x-file.npy', x) # 保存为npy文件
```

* 我们现在可以将存储在文件中的数据读回内存。


```python
x2 = np.load('x-file.npy', allow_pickle=True)
x2
```




    array([0, 1, 2, 3], dtype=int32)



* 我们可以存储一个张量列表，然后把它们读回内存。


```python
y = tf.zeros(4)
np.save('xy-files.npy', [x, y]) # 存储一个张量列表
x2, y2 = np.load('xy-files.npy', allow_pickle=True) # 将张量列表读回内存
(x2, y2)
```




    (array([0., 1., 2., 3.]), array([0., 0., 0., 0.]))



* 我们甚至可以(**写入或读取从字符串映射到张量的字典**)。当我们要读取或写入模型中的所有权重时，这很方便。


```python
mydict = {'x': x, 'y': y} # 将张量映射到字典
np.save('mydict.npy', mydict)
mydict2 = np.load('mydict.npy', allow_pickle=True)
mydict2
```




    array({'x': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 2, 3], dtype=int32)>, 'y': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>},
          dtype=object)



## 加载和保存模型参数

* 深度学习框架提供了内置函数来保存和加载整个网络。
    * 需要注意的一个重要细节是，这将*保存模型的参数而不是保存整个模型*。
    * 例如，如果我们有一个3层多层感知机，我们需要单独指定结构。*因为模型本身可以包含任意代码，所以模型本身难以序列化*。因此，为了恢复模型，我们需要用代码生成结构，然后从磁盘加载参数。让我们从熟悉的多层感知机开始尝试一下。


```python
class MLP(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.flatten = tf.keras.layers.Flatten()
        self.hidden = tf.keras.layers.Dense(units=256, activation=tf.nn.relu)
        self.out = tf.keras.layers.Dense(units=10)

    def call(self, inputs):
        x = self.flatten(inputs)
        x = self.hidden(x)
        return self.out(x)

net = MLP()
X = tf.random.uniform((2, 20))
Y = net(X)
```

* 接下来，我们使用`sava_weights`函数将模型的参数存储为一个叫做“mlp.params”的文件。


```python
net.save_weights('mlp.params')
```

* 为了恢复模型，我们[**实例化了原始多层感知机模型的一个备份。**]
    * 我们没有随机初始化模型参数，而是(**直接读取文件中存储的参数。**)


```python
clone = MLP()
clone.load_weights('mlp.params') # 初始化模型再加载参数
```




    <tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd648f496a0>



* 由于两个实例具有相同的模型参数，在输入相同的`X`时，两个实例的计算结果应该相同。让我们来验证一下。


```python
Y_clone = clone(X)
Y_clone == Y
```




    <tf.Tensor: shape=(2, 10), dtype=bool, numpy=
    array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
             True],
           [ True,  True,  True,  True,  True,  True,  True,  True,  True,
             True]])>


# GPU

* 使用单个GPU，然后是如何使用多个GPU和多个服务器（具有多个GPU）来提高模型计算性能。
* 具体来说，我们将讨论如何使用单个NVIDIA GPU进行计算。
    * 首先，确保至少安装了一个NVIDIA GPU。
    * 然后，下载[NVIDIA驱动和CUDA](https://developer.nvidia.com/cuda-downloads)并按照提示设置适当的路径。当这些准备工作完成，就可以使用`nvidia-smi`命令来(**查看显卡信息。**)
* 对于深度学习计算经常会使用多个GPU，对于大多数桌面计算机来说，这可能是奢侈的，但在云中很容易获得，例如，通过使用AWS EC2的多GPU实例。


```python
!nvidia-smi
```

    Sat Nov 27 10:07:27 2021       
    +-----------------------------------------------------------------------------+
    | NVIDIA-SMI 465.89       Driver Version: 465.89       CUDA Version: 11.3     |
    |-------------------------------+----------------------+----------------------+
    | GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
    |                               |                      |               MIG M. |
    |===============================+======================+======================|
    |   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |
    | N/A   42C    P8     6W /  N/A |    356MiB /  6144MiB |      1%      Default |
    |                               |                      |                  N/A |
    +-------------------------------+----------------------+----------------------+
                                                                                   
    +-----------------------------------------------------------------------------+
    | Processes:                                                                  |
    |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
    |        ID   ID                                                   Usage      |
    |=============================================================================|
    |    0   N/A  N/A      1244    C+G   ...cw5n1h2txyewy\LockApp.exe    N/A      |
    |    0   N/A  N/A      6020    C+G   ...ekyb3d8bbwe\YourPhone.exe    N/A      |
    |    0   N/A  N/A      6180    C+G   C:\WINDOWS\System32\dwm.exe     N/A      |
    |    0   N/A  N/A     16764    C+G   C:\WINDOWS\explorer.exe         N/A      |
    |    0   N/A  N/A     19744    C+G   ...nputApp\TextInputHost.exe    N/A      |
    |    0   N/A  N/A     20788    C+G   ...5n1h2txyewy\SearchApp.exe    N/A      |
    |    0   N/A  N/A     21320    C+G   ...lPanel\SystemSettings.exe    N/A      |
    |    0   N/A  N/A     22164    C+G   ...TeamViewer\TeamViewer.exe    N/A      |
    |    0   N/A  N/A     23152    C+G   ...ge\Application\msedge.exe    N/A      |
    |    0   N/A  N/A     24896    C+G   ...bbwe\Microsoft.Photos.exe    N/A      |
    |    0   N/A  N/A     25116    C+G   ...8wekyb3d8bbwe\Cortana.exe    N/A      |
    |    0   N/A  N/A     26084    C+G   ...ram Files\PicGo\PicGo.exe    N/A      |
    +-----------------------------------------------------------------------------+
    

## 计算设备

* 我们可以指定用于存储和计算的设备，如CPU和GPU。默认情况下，张量是在内存中创建的，然后使用CPU计算它。


```python
import tensorflow as tf

tf.device('/CPU:0'), tf.device('/GPU:0'), tf.device('/GPU:1')
```




    (<tensorflow.python.eager.context._EagerDeviceContext at 0x2343b20df00>,
     <tensorflow.python.eager.context._EagerDeviceContext at 0x2343b20df40>,
     <tensorflow.python.eager.context._EagerDeviceContext at 0x2343b214b40>)



* 我们可以(**查询可用gpu的数量。**)


```python
len(tf.config.experimental.list_physical_devices('GPU')) # 结果显示可用GPU只有一个。
```




    1



* 现在我们定义了两个方便的函数，[**这两个函数允许我们在请求的GPU不存在的情况下运行代码。**]


```python
def try_gpu(i=0):  #@save
    """如果存在，则返回gpu(i)，否则返回cpu()。"""
    if len(tf.config.experimental.list_physical_devices('GPU')) >= i + 1:
        return tf.device(f'/GPU:{i}')
    return tf.device('/CPU:0')

def try_all_gpus():  #@save
    """返回所有可用的GPU，如果没有GPU，则返回[cpu(),]。"""
    num_gpus = len(tf.config.experimental.list_physical_devices('GPU'))
    devices = [tf.device(f'/GPU:{i}') for i in range(num_gpus)]
    return devices if devices else [tf.device('/CPU:0')]

try_gpu(), try_gpu(10), try_all_gpus()
```




    (<tensorflow.python.eager.context._EagerDeviceContext at 0x2343b272040>,
     <tensorflow.python.eager.context._EagerDeviceContext at 0x2343b272380>,
     [<tensorflow.python.eager.context._EagerDeviceContext at 0x2343b2723c0>])



## 张量与gpu

* 默认情况下，张量是在CPU上创建的。我们可以[**查询张量所在的设备。**]


```python
x = tf.constant([1, 2, 3])
x.device
```




    '/job:localhost/replica:0/task:0/device:CPU:0'



* 需要注意的是，无论何时我们要对多个项进行操作，它们都必须在同一个设备上。例如，如果我们对两个张量求和，我们需要确保两个张量都位于同一个设备上，否则框架将不知道在哪里存储结果，甚至不知道在哪里执行计算。

### 存储在GPU上

* 有几种方法可以在GPU上存储张量。
* 例如，我们可以在*创建张量时指定存储设备*。
* 接下来，我们在第一个`gpu`上创建张量变量`X`。在GPU上创建的张量只消耗这个GPU的显存。
    * 我们可以使用`nvidia-smi`命令查看显存使用情况。一般来说，我们需要确保不创建超过GPU显存限制的数据。


```python
with try_gpu():
    X = tf.ones((2, 3))
X.device, X
```




    ('/job:localhost/replica:0/task:0/device:GPU:0',
     <tf.Tensor: shape=(2, 3), dtype=float32, numpy=
     array([[1., 1., 1.],
            [1., 1., 1.]], dtype=float32)>)



* 假设你至少有两个GPU，下面的代码将在(**第二个GPU上创建一个随机张量。**)(但是我的电脑实际只有一个GPU）


```python
with try_gpu(1):
    Y = tf.random.uniform((2, 3))
Y.device, Y 
```




    ('/job:localhost/replica:0/task:0/device:CPU:0',
     <tf.Tensor: shape=(2, 3), dtype=float32, numpy=
     array([[0.1963296 , 0.29300058, 0.94139194],
            [0.2455548 , 0.59477484, 0.2650982 ]], dtype=float32)>)



* 因为第二个gpu不存在，所以`try_gpu`函数默认返回CPU。

### 复制

* 如果我们[**要计算`X + Y`，我们需要决定在哪里执行这个操作**]。
* 如下图所示，我们可以将`X`传输到第二个GPU并在那里执行操作。
* 不要简单地`X`加上`Y`，因为这会导致异常。运行时引擎不知道该怎么做：它在同一设备上找不到数据会导致失败。由于`Y`位于第二个GPU上，所以我们需要将`X`移到那里，然后才能执行相加运算。
![](https://zjpicture.oss-cn-beijing.aliyuncs.com/img/20211127102311.png)


```python
with try_gpu(1):
    Z = X
X.device, Z.device, X is Z # 因为只有一个GPU，实际没有复制成功，只是同一变量的引用
```




    ('/job:localhost/replica:0/task:0/device:GPU:0',
     '/job:localhost/replica:0/task:0/device:GPU:0',
     True)



[**现在数据在同一个GPU上（`Z`和`Y`都在），我们可以将它们相加。**]



```python
Y + Z
```




    <tf.Tensor: shape=(2, 3), dtype=float32, numpy=
    array([[1.1963296, 1.2930006, 1.941392 ],
           [1.2455548, 1.5947748, 1.2650982]], dtype=float32)>



* 假设变量`Z`已经存在于第二个GPU上。如果我们仍然在同一个设备作用域下调用`Z2 = Z`会怎么样？它将返回`Z`，而不会复制并分配新内存。


```python
with try_gpu(1):
    Z2 = Z
Z2 is Z
```




    True



### 旁注

* 在设备（CPU、GPU和其他机器）之间传输数据比计算慢得多。这也使得并行化变得更加困难，因为我们必须等待数据被发送（或者接收），然后才能继续进行更多的操作。这就是为什么拷贝操作要格外小心。
* 此外，除非你知道自己在做什么，否则，一次执行几个操作比代码中散布的许多单个操作要好得多。如果一个设备必须等待另一个设备才能执行其他操作，那么这样的操作可能会阻塞。


## 神经网络与GPU

* 类似地，神经网络模型可以指定设备。下面的代码将模型参数放在GPU上。


```python
strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    net = tf.keras.models.Sequential([
        tf.keras.layers.Dense(1)])
```

    WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.
    INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
    

* 当输入为GPU上的张量时，模型将在同一GPU上计算结果。


```python
Y = net(X)
X.device,Y, Y.device
```




    ('/job:localhost/replica:0/task:0/device:GPU:0',
     <tf.Tensor: shape=(2, 1), dtype=float32, numpy=
     array([[1.2583696],
            [1.2583696]], dtype=float32)>,
     '/job:localhost/replica:0/task:0/device:GPU:0')



* 让我们(**确认模型参数存储在同一个GPU上。**)


```python
net.layers[0].weights[0].device, net.layers[0].weights[1].device
```




    ('/job:localhost/replica:0/task:0/device:GPU:0',
     '/job:localhost/replica:0/task:0/device:GPU:0')



* 总之，只要所有的数据和参数都在同一个设备上，我们就可以有效地学习模型。
